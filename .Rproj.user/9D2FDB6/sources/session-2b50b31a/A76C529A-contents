---
title: "main"
author: "Takuto Yoshida"
date: "2025-11-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
################################################################################
# main.R - HCCå†ç™ºäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# 
# Description: 
#   å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’çµ±åˆå®Ÿè¡Œ
#   ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»å¯è¦–åŒ–ã¾ã§
#
# Author: Takuto Yoshida
# Date: 2024-11-07
################################################################################

# ========================================================================
# 0. ç’°å¢ƒè¨­å®š
# ========================================================================

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆsetwd()ã¯ä½¿ã‚ãªã„ï¼‰
config <- yaml::read_yaml("/Users/yoshidatakuto/Dropbox/Hokkaido University/å¤§å­¦é™¢åŒ»å­¦é™¢/Borderline HCC/Prediction model_Project1/04_Script/config/settings.yaml")
PROJECT_DIR <- config$paths$base_dir

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèªã®ã¿ï¼ˆå¤‰æ›´ã¯ã—ãªã„ï¼‰
current_wd <- getwd()
message(sprintf("Current working directory: %s", current_wd))
message(sprintf("Project directory (from config): %s", PROJECT_DIR))

# å®Ÿè¡Œæ™‚é–“ã®è¨˜éŒ²é–‹å§‹
start_time <- Sys.time()

message("\n")
message("================================================================================")
message("                    HCC Recurrence Prediction Model Pipeline                    ")
message("================================================================================")
message(sprintf("Started at: %s", format(start_time, "%Y-%m-%d %H:%M:%S")))
message(sprintf("Project base: %s", basename(PROJECT_DIR)))
message("")


```
```{r}
# ä¸‹è¨˜ã‚’ä¸€åº¦ã ã‘å®Ÿè¡Œ
#.Rmdã‹ã‚‰.Rãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰
library(knitr)

script_dir <- file.path(PROJECT_DIR, "04_Script", "R")

# .Rmdãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
rmd_files <- list.files(script_dir, pattern = "\\.Rmd$", full.names = TRUE)

for (rmd_file in rmd_files) {
  # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.Rmd â†’ .Rï¼‰
  r_file <- sub("\\.Rmd$", ".R", rmd_file)

  # Rã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ä¿å­˜
  knitr::purl(rmd_file, output = r_file, quiet = TRUE, documentation = 0)

  message(sprintf("Created: %s", basename(r_file)))
}

# ========================================================================
# 1. ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
# ========================================================================

message("\nğŸ“š Loading source files...")
message("----------------------------------------")

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
script_dir <- file.path(PROJECT_DIR, "04_Script", "R")

# .Rãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆ.Rmdã§ã¯ãªãï¼‰
source_files <- c(
  "00_setup.R",      # .R ã«å¤‰æ›´
  "01_data_loader.R",
  "02_data_cleaner.R",
  "03_feature_engineer.R",
  "04_data_splitter.R",
  "05_model_builder.R",
  "06_model_evaluator.R",
  "07_visualizer.R"
)

for (file in source_files) {
  file_path <- file.path(script_dir, file)
  if (file.exists(file_path)) {
    source(file_path)
    message(sprintf("  âœ“ Loaded: %s", file))
  } else {
    warning(sprintf("  âœ— File not found: %s", file))
  }
}
```

```{r}
# ========================================================================
# 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
# ========================================================================

message("\nğŸš€ Initializing project...")
message("----------------------------------------")

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
config_path <- file.path(PROJECT_DIR, "04_Script", "config", "settings.yaml")
variables_path <- file.path(PROJECT_DIR, "04_Script", "config", "variables.yaml")

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
if (!file.exists(config_path)) {
  stop(sprintf("Configuration file not found: %s", config_path))
}
if (!file.exists(variables_path)) {
  stop(sprintf("Variables file not found: %s", variables_path))
}

# è¨­å®šã®èª­ã¿è¾¼ã¿
config <- yaml::read_yaml(config_path)
variables <- yaml::read_yaml(variables_path)

message(sprintf("  âœ“ Configuration loaded from: %s", basename(config_path)))
message(sprintf("  âœ“ Variables loaded from: %s", basename(variables_path)))

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®åˆæœŸåŒ–
paths <- initialize_project(config_path, verbose = FALSE)
```

```{r}
# ========================================================================
# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ========================================================================

message("\nğŸ“Š Data Processing Pipeline")
message("----------------------------------------")

# 3.1 ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
message("\n[Step 1/7] Loading and preparing data...")
dm <- load_and_prepare_data(
  config_path = config_path,
  variables_path = variables_path
)

# 3.2 ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
message("\n[Step 2/7] Cleaning data...")
dm <- clean_data_pipeline(dm, config, variables)

# 3.3 ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
message("\n[Step 3/7] Engineering features...")
dm <- feature_engineering_pipeline(dm, config, variables)

# æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
final_data <- dm$get_current()

# æ¬ æå€¤ã®è£œå®Œ
final_data <- handle_missing_values(final_data, config, method = "median")

message(sprintf("\n  âœ“ Final dataset: %d rows Ã— %d columns", 
               nrow(final_data), ncol(final_data)))

# ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
if (config$runtime$save_intermediate) {
  saveRDS(final_data, file.path(paths$output, "processed_data.rds"))
  message("  âœ“ Processed data saved")
}
```

```{r}
# ========================================================================
# 4. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
# ========================================================================

message("\n[Step 4/7] Splitting data...")
message("----------------------------------------")

# åˆ†å‰²æ–¹æ³•ã®å–å¾—
split_method <- ifelse(!is.null(config$model$split_method), 
                       config$model$split_method, 
                       "temporal")

# äºˆæ¸¬æœŸé–“ã®å–å¾—
prediction_months <- ifelse(!is.null(config$model$prediction_time),
                           config$model$prediction_time,
                           24)

# åŸºæº–æ—¥ã®è¨­å®š
reference_date <- Sys.Date()
if (!is.null(config$model$reference_date)) {
  reference_date <- as.Date(config$model$reference_date)
}

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Ÿè¡Œ
split_data <- split_data_pipeline(
  df = final_data,
  config = config,
  method = split_method,
  prediction_months = prediction_months,
  reference_date = "auto",
  create_cv = TRUE
)

# åˆ†å‰²çµæœã®ä¿å­˜
if (config$runtime$save_intermediate) {
  save_split(split_data, file.path(paths$output_models, "data_split.rds"))
  message("  âœ“ Data split saved")
}
```


```{r}
# ========================================================================
# 5. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ========================================================================

message("\n[Step 5/7] Building models...")
message("----------------------------------------")

# å…¨ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ===== Step 1: time2yã®ã‚¼ãƒ­å€¤ã‚’ä¿®æ­£ =====
fix_zero_times <- function(data) {
  if ("time2y" %in% names(data)) {
    zero_idx <- which(data$time2y <= 0)
    if (length(zero_idx) > 0) {
      data$time2y[zero_idx] <- 0.1
      message(sprintf("Fixed %d zero/negative time values", length(zero_idx)))
    }
  }
  return(data)
}

# ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨
split_data_clean$train <- fix_zero_times(split_data_clean$train)
split_data_clean$val <- fix_zero_times(split_data_clean$val)
split_data_clean$test <- fix_zero_times(split_data_clean$test)

# ===== Step 2: YAMLã‚’å†èª­ã¿è¾¼ã¿ =====
variables <- yaml::read_yaml(file.path(PROJECT_DIR, "04_Script/config/variables.yaml"))
config <- yaml::read_yaml(file.path(PROJECT_DIR, "04_Script/config/settings.yaml"))

# ===== Step 3: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†èª­ã¿è¾¼ã¿ =====
source(file.path(PROJECT_DIR, "04_Script/R/05_model_builder.R"))

# ===== Step 4: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ =====
USE_VARIABLE_SET <- "postop_pathology_custom"

models <- build_all_models(
  split_data = split_data_clean,
  config = config,
  variables = variables,
  variable_set_name = USE_VARIABLE_SET
)

# ===== Step 5: çµæœç¢ºèª =====
message("\n=== Model Results ===")
for (model_name in names(models)) {
  if (!is.null(models[[model_name]])) {
    if (inherits(models[[model_name]], "coxph")) {
      n_vars <- length(coef(models[[model_name]]))
    } else {
      n_vars <- length(attr(models[[model_name]], "selected_vars"))
    }
    message(sprintf("âœ“ %s: %d variables", model_name, n_vars))
  } else {
    message(sprintf("âœ— %s: Failed", model_name))
  }
}

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
save_models(models, file.path(paths$output_models, "all_models.rds"))

# ãƒ¢ãƒ‡ãƒ«æ•°ã®ç¢ºèª
n_successful <- sum(!sapply(models, is.null))
message(sprintf("\n  âœ“ Successfully built %d/%d models", 
               n_successful, length(models)))
```

```{r}
# ========================================================================
# 5.5 è©•ä¾¡å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆä¿®æ­£ç‰ˆï¼‰
# ========================================================================

message("\nğŸ§¹ Final cleaning before evaluation...")
message("----------------------------------------")

# å¤‰æ•°åã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼ˆè¿½åŠ ï¼‰
clean_names_final <- function(data) {
  old_names <- names(data)
  new_names <- gsub(" ", "_", old_names)
  new_names <- gsub("\\+", "_plus", new_names)
  new_names <- gsub("Â±", "_pm", new_names)
  names(data) <- new_names
  return(data)
}

# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¤‰æ•°åã‚’ã‚¯ãƒªãƒ¼ãƒ³
split_data_clean$train <- clean_names_final(split_data_clean$train)
split_data_clean$val <- clean_names_final(split_data_clean$val)
split_data_clean$test <- clean_names_final(split_data_clean$test)

# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
clean_for_evaluation <- function(data) {
  # 1. å®Œå…¨ã«ä¸è¦ãªå¤‰æ•°ã‚’å‰Šé™¤
  vars_to_remove <- c(
    # æ—¥ä»˜ç³»ã®ä¸è¦å¤‰æ•°
    "first_visit_dt", "adm_dt",  # â† ã“ã‚Œã‚‰ã¯æœ¬å½“ã«ä¸è¦
    # BMI_categoryé–¢é€£
    "BMI_category", "BMI_categoryNormal", "BMI_categoryOverweight", "BMI_categoryObese",
    # ãã®ä»–ä¸è¦
    "im", "im1", "Pringle", 
    "fc_inf_numeric", "sm_numeric", "sf_numeric", "fc_numeric",
    "æœ€å¤§å¾„", "å€‹æ•°", "æ€§åˆ¥"
  )
  
  for (var in vars_to_remove) {
    if (var %in% names(data)) {
      data[[var]] <- NULL
      message(sprintf("  Removed: %s", var))
    }
  }
  
  # 2. recur_dateã¯æ¬ æã®ã¾ã¾æ®‹ã™ï¼ˆå†ç™ºãªã—æƒ…å ±ã¨ã—ã¦é‡è¦ï¼‰
  # ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«ã«ã¯ä½¿ã‚ãªã„ã®ã§å•é¡Œãªã—
  
  # 3. ä»–ã®å¤‰æ•°ã®æ¬ æå€¤ã‚’è£œå®Œ
  numeric_vars <- names(data)[sapply(data, is.numeric)]
  # recur_dateã¯é™¤å¤–ã—ã¦è£œå®Œ
  numeric_vars <- setdiff(numeric_vars, "recur_date")
  
  for (var in numeric_vars) {
    if (any(is.na(data[[var]]))) {
      med_val <- median(data[[var]], na.rm = TRUE)
      if (is.finite(med_val)) {
        data[[var]][is.na(data[[var]])] <- med_val
      }
    }
  }
  
  # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°
  factor_vars <- names(data)[sapply(data, function(x) is.factor(x) || is.character(x))]
  # recur_dateã¨death_causeç³»ã¯é™¤å¤–
  factor_vars <- setdiff(factor_vars, c("recur_date", "death_cause", "death_cause4"))
  
  for (var in factor_vars) {
    if (any(is.na(data[[var]]))) {
      tab <- table(data[[var]], useNA = "no")
      if (length(tab) > 0) {
        mode_val <- names(tab)[which.max(tab)]
        data[[var]][is.na(data[[var]])] <- mode_val
      }
    }
  }
  
  # è«–ç†å¤‰æ•°
  logical_vars <- names(data)[sapply(data, is.logical)]
  for (var in logical_vars) {
    if (any(is.na(data[[var]]))) {
      data[[var]][is.na(data[[var]])] <- FALSE
    }
  }
  
  return(data)
}

# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
split_data_clean$train <- clean_for_evaluation(split_data_clean$train)
split_data_clean$val <- clean_for_evaluation(split_data_clean$val)
split_data_clean$test <- clean_for_evaluation(split_data_clean$test)

# æœ€çµ‚ç¢ºèªï¼ˆrecur_dateä»¥å¤–ã®NAç¢ºèªï¼‰
message("\n=== Final NA check (excluding recur_date) ===")
check_na <- function(data, name) {
  # recur_dateä»¥å¤–ã®åˆ—ã§NAã‚’ãƒã‚§ãƒƒã‚¯
  cols_to_check <- setdiff(names(data), c("recur_date", "death_cause", "death_cause4"))
  na_count <- sum(is.na(data[, cols_to_check]))
  message(sprintf("%s: %d NAs (excluding recur_date)", name, na_count))
  
  if (na_count > 0) {
    na_cols <- colSums(is.na(data[, cols_to_check]))
    na_cols <- na_cols[na_cols > 0]
    if (length(na_cols) > 0) {
      message(sprintf("  Remaining NAs in %s:", name))
      print(na_cols)
    }
  }
  return(na_count)
}

train_na <- check_na(split_data_clean$train, "Train")
val_na <- check_na(split_data_clean$val, "Val")
test_na <- check_na(split_data_clean$test, "Test")

# ã™ã¹ã¦0ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
if (train_na + val_na + test_na == 0) {
  message("\nâœ… Perfect! No problematic NAs remaining!")
  message("   (recur_date NAs are kept intentionally as 'no recurrence' indicator)")
}
```
```{r}
# ========================================================================
# 6. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# ========================================================================

message("\n========================================")
message("FIXING EVALUATION DATA PREPARATION")
message("========================================\n")

# Step 1: ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹é–¢æ•°
prepare_clean_split_data <- function(split_data, variables_to_use = NULL) {
  
  message("Preparing clean split data for evaluation...")
  
  # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸå¤‰æ•°ã‚’å–å¾—
  if (is.null(variables_to_use) && exists("models") && !is.null(attr(models, "train_data"))) {
    train_data_used <- attr(models, "train_data")
    variables_to_use <- setdiff(names(train_data_used), c("surv_obj"))
    message(sprintf("  Using %d variables from model training", length(variables_to_use)))
  }
  
  # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
  clean_dataset <- function(data, name) {
    message(sprintf("\n  Cleaning %s dataset...", name))
    
    # å¿…è¦ãªå¤‰æ•°ã®ã¿é¸æŠ
    if (!is.null(variables_to_use)) {
      # time2yã¨recur_2yã¯å¿…é ˆ
      required_vars <- unique(c("time2y", "recur_2y", variables_to_use))
      available_vars <- intersect(required_vars, names(data))
      missing_vars <- setdiff(required_vars, names(data))
      
      if (length(missing_vars) > 0) {
        message(sprintf("    Warning: %d variables missing", length(missing_vars)))
        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœ€åˆã®5å€‹ã‚’è¡¨ç¤º
        if (length(missing_vars) <= 5) {
          message(sprintf("    Missing: %s", paste(missing_vars, collapse = ", ")))
        }
      }
      
      data <- data[, available_vars, drop = FALSE]
      message(sprintf("    Selected %d variables", ncol(data)))
    }
    
    # é‡è¤‡ã—ãŸãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’å‰Šé™¤
    # TRUE/FALSEãŒé‡è¤‡ã—ã¦ã„ã‚‹å¤‰æ•°ã‚’æ¤œå‡º
    dup_patterns <- c("TRUETRUE", "FALSEFALSE", "TRUEFALSE", "FALSETRUE")
    for (pattern in dup_patterns) {
      bad_vars <- grep(pattern, names(data), value = TRUE)
      if (length(bad_vars) > 0) {
        data <- data[, !names(data) %in% bad_vars, drop = FALSE]
        message(sprintf("    Removed %d duplicate variables with pattern '%s'", 
                       length(bad_vars), pattern))
      }
    }
    
    # surv_objã‚’ä½œæˆ
    if (all(c("time2y", "recur_2y") %in% names(data))) {
      data$surv_obj <- survival::Surv(
        time = data$time2y,
        event = as.numeric(as.character(data$recur_2y) %in% c("TRUE", "1"))
      )
      message("    Created surv_obj")
    }
    
    return(data)
  }
  
  # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‡¦ç†
  result <- list()
  if (!is.null(split_data$train)) {
    result$train <- clean_dataset(split_data$train, "train")
  }
  if (!is.null(split_data$val)) {
    result$val <- clean_dataset(split_data$val, "val")
  }
  if (!is.null(split_data$test)) {
    result$test <- clean_dataset(split_data$test, "test")
  }
  
  # ãƒ¡ã‚¿æƒ…å ±ã‚’ã‚³ãƒ”ãƒ¼
  result$meta <- split_data$meta
  result$indices <- split_data$indices
  
  return(result)
}

# Step 2: ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£
split_data_fixed <- prepare_clean_split_data(split_data_clean)

# Step 3: ç¢ºèª
message("\nğŸ“Š Fixed data summary:")
for (set_name in c("train", "val", "test")) {
  if (!is.null(split_data_fixed[[set_name]])) {
    data <- split_data_fixed[[set_name]]
    message(sprintf("\n%s:", set_name))
    message(sprintf("  Dimensions: %d Ã— %d", nrow(data), ncol(data)))
    message(sprintf("  Has surv_obj: %s", "surv_obj" %in% names(data)))
    message(sprintf("  Has time2y: %s", "time2y" %in% names(data)))
    message(sprintf("  Has recur_2y: %s", "recur_2y" %in% names(data)))
  }
}

# Step 4: ä¿®æ­£ç‰ˆã®è©•ä¾¡ã‚’å®Ÿè¡Œ
message("\n========================================")
message("RE-RUNNING EVALUATION WITH FIXED DATA")
message("========================================\n")

# evaluate_all_modelsã‚’å†å®šç¾©ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
evaluate_all_models_fixed <- function(models, split_data_fixed) {
  
  results <- list()
  summary_table <- data.frame()
  
  for (model_name in names(models)) {
    model <- models[[model_name]]
    
    if (!is.null(model)) {
      message(sprintf("\n--- Evaluating: %s ---", model_name))
      
      # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡
      for (set_name in c("train", "val", "test")) {
        data <- split_data_fixed[[set_name]]
        
        if (!is.null(data) && "surv_obj" %in% names(data)) {
          
          tryCatch({
            # C-indexã®è¨ˆç®—
            if (inherits(model, "coxph")) {
              pred <- predict(model, newdata = data, type = "risk")
            } else if (inherits(model, "list") && "model" %in% names(model) && !is.null(model$model)) {
              pred <- predict(model$model, newdata = data, type = "risk")
            } else if (inherits(model, "lasso_cox")) {
              # LASSOã®å ´åˆã®å‡¦ç†
              X_vars <- intersect(colnames(model$X), names(data))
              if (length(X_vars) > 0) {
                # ç°¡æ˜“ç‰ˆï¼šåˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ã®ã¿ä½¿ç”¨
                formula_str <- paste("~ -1 +", paste(model$selected_vars[model$selected_vars %in% names(data)], collapse = " + "))
                X_new <- model.matrix(as.formula(formula_str), data = data)
                
                # æ¬ è½ã—ã¦ã„ã‚‹åˆ—ã‚’0ã§åŸ‹ã‚ã‚‹
                X_full <- matrix(0, nrow = nrow(data), ncol = ncol(model$X))
                colnames(X_full) <- colnames(model$X)
                common_cols <- intersect(colnames(X_new), colnames(model$X))
                if (length(common_cols) > 0) {
                  X_full[, common_cols] <- X_new[, common_cols]
                }
                
                pred <- predict(model$glmnet_model, newx = X_full, s = model$lambda_min, type = "link")[, 1]
              } else {
                pred <- rep(0, nrow(data))
              }
            } else {
              pred <- rep(0, nrow(data))
            }
            
            # C-indexè¨ˆç®—
            c_result <- survival::concordance(data$surv_obj ~ pred, reverse = TRUE)
            c_index <- c_result$concordance
            
            message(sprintf("  %s: C-index = %.3f", set_name, c_index))
            
            # çµæœã‚’ä¿å­˜
            if (!model_name %in% names(results)) {
              results[[model_name]] <- list()
            }
            results[[model_name]][[set_name]] <- list(c_index = c_index)
            
          }, error = function(e) {
            message(sprintf("  %s: Error - %s", set_name, e$message))
          })
        }
      }
      
      # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¿½åŠ 
      if (model_name %in% names(results)) {
        summary_row <- data.frame(
          model = model_name,
          c_index_train = ifelse("train" %in% names(results[[model_name]]), 
                                results[[model_name]]$train$c_index, NA),
          c_index_val = ifelse("val" %in% names(results[[model_name]]), 
                              results[[model_name]]$val$c_index, NA),
          c_index_test = ifelse("test" %in% names(results[[model_name]]), 
                               results[[model_name]]$test$c_index, NA)
        )
        summary_table <- rbind(summary_table, summary_row)
      }
    }
  }
  
  # ã‚½ãƒ¼ãƒˆ
  if (nrow(summary_table) > 0) {
    summary_table <- summary_table[order(summary_table$c_index_test, decreasing = TRUE, na.last = TRUE), ]
    rownames(summary_table) <- NULL
  }
  
  return(list(
    results = results,
    summary = summary_table
  ))
}

# å®Ÿè¡Œ
eval_results_fixed <- evaluate_all_models_fixed(models, split_data_fixed)

# çµæœè¡¨ç¤º
if (!is.null(eval_results_fixed$summary) && nrow(eval_results_fixed$summary) > 0) {
  message("\nğŸ“Š EVALUATION RESULTS (FIXED):")
  print(eval_results_fixed$summary, digits = 3)
  
  # æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¦ãƒ³ãƒˆ
  n_success <- sum(!is.na(eval_results_fixed$summary$c_index_test))
  message(sprintf("\nâœ… Successfully evaluated %d/%d models", 
                 n_success, nrow(eval_results_fixed$summary)))
}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ä¿å­˜
evaluation_results <- eval_results_fixed
message("\nğŸ’¾ Results saved as 'evaluation_results'")
```




```{r}
# ========================================================================
# å¯è¦–åŒ–å‰ã®æœ€çµ‚ç¢ºèª
# ========================================================================

message("\n========================================")
message("FINAL CHECK BEFORE VISUALIZATION")
message("========================================\n")

# 1. è©•ä¾¡çµæœã®ç¢ºèª
if (exists("evaluation_results") && !is.null(evaluation_results$summary)) {
  message("ğŸ“Š Evaluation results summary:")
  print(evaluation_results$summary[, c("model", "c_index_test")], digits = 3)
  
  # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š
  best_idx <- which.max(evaluation_results$summary$c_index_test)
  if (length(best_idx) > 0) {
    best_model <- evaluation_results$summary[best_idx, ]
    message(sprintf("\nğŸ† Best model: %s (C-index = %.3f)", 
                   best_model$model, best_model$c_index_test))
  }
}

# 2. ç°¡æ˜“ç‰ˆã®å¯è¦–åŒ–é–¢æ•°ï¼ˆC-indexãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰
create_simple_visualizations <- function(evaluation_results, models, output_dir) {
  
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  plots <- list()
  
  # 1. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
  tryCatch({
    message("\nğŸ“Š Creating model comparison plot...")
    
    summary_df <- evaluation_results$summary
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    plot_data <- tidyr::pivot_longer(
      summary_df,
      cols = starts_with("c_index"),
      names_to = "dataset",
      values_to = "c_index"
    )
    
    plot_data$dataset <- gsub("c_index_", "", plot_data$dataset)
    plot_data$dataset <- factor(plot_data$dataset, levels = c("train", "val", "test"))
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    p <- ggplot(plot_data, aes(x = model, y = c_index, fill = dataset)) +
      geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
      geom_hline(yintercept = 0.5, linetype = "dashed", color = "red") +
      scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
      labs(
        title = "Model Performance Comparison (C-index)",
        x = "Model",
        y = "C-index",
        fill = "Dataset"
      ) +
      theme_minimal() +
      theme(
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "top"
      ) +
      scale_fill_brewer(palette = "Set2")
    
    # ä¿å­˜
    ggsave(
      file.path(output_dir, "model_comparison.pdf"),
      plot = p, width = 10, height = 6
    )
    
    plots$comparison <- p
    message("  âœ“ Model comparison plot created")
    
  }, error = function(e) {
    message(sprintf("  âœ— Error in comparison plot: %s", e$message))
  })
  
  # 2. å¤‰æ•°é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
  tryCatch({
    message("\nğŸ“Š Creating variable importance plot...")
    
    # å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å¤‰æ•°ã‚’é›†è¨ˆ
    var_frequency <- table(unlist(lapply(models, function(m) {
      if (inherits(m, "coxph")) {
        names(coef(m))
      } else if (inherits(m, "list") && "selected_vars" %in% names(m)) {
        m$selected_vars
      } else {
        NULL
      }
    })))
    
    if (length(var_frequency) > 0) {
      var_df <- data.frame(
        variable = names(var_frequency),
        frequency = as.numeric(var_frequency)
      )
      var_df <- var_df[order(var_df$frequency, decreasing = TRUE), ]
      var_df <- head(var_df, 20)
      
      var_df$variable <- factor(var_df$variable, levels = rev(var_df$variable))
      
      p2 <- ggplot(var_df, aes(x = variable, y = frequency)) +
        geom_bar(stat = "identity", fill = "steelblue") +
        coord_flip() +
        labs(
          title = "Variable Selection Frequency Across Models",
          x = "Variable",
          y = "Frequency"
        ) +
        theme_minimal()
      
      ggsave(
        file.path(output_dir, "variable_frequency.pdf"),
        plot = p2, width = 8, height = 10
      )
      
      plots$var_importance <- p2
      message("  âœ“ Variable importance plot created")
    }
    
  }, error = function(e) {
    message(sprintf("  âœ— Error in variable plot: %s", e$message))
  })
  
  # 3. çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆHTML/CSVï¼‰
  tryCatch({
    message("\nğŸ“Š Creating results table...")
    
    # CSVä¿å­˜
    write.csv(
      evaluation_results$summary,
      file.path(output_dir, "model_performance.csv"),
      row.names = FALSE
    )
    
    message("  âœ“ Results table saved")
    
  }, error = function(e) {
    message(sprintf("  âœ— Error in table: %s", e$message))
  })
  
  return(plots)
}

# 3. å¯è¦–åŒ–å®Ÿè¡Œ
message("\n========================================")
message("[Step 7/7] Creating visualizations...")
message("========================================")

# ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆã®å¯è¦–åŒ–ã‚’å®Ÿè¡Œ
plots_simple <- create_simple_visualizations(
  evaluation_results = evaluation_results,
  models = models,
  output_dir = paths$output_figures
)

# ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å¯è¦–åŒ–é–¢æ•°ã‚‚è©¦ã™ï¼ˆã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‚ç¶šè¡Œï¼‰
plots_original <- tryCatch({
  visualize_all_results(
    evaluation_results = evaluation_results,
    models = models,
    output_dir = paths$output_figures,
    config = config
  )
}, error = function(e) {
  message(sprintf("\nNote: Some advanced visualizations failed: %s", e$message))
  message("Using simplified visualizations instead.")
  NULL
})

# ä½œæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒƒãƒˆæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
n_plots <- sum(!sapply(c(plots_simple, plots_original), is.null))
message(sprintf("\nâœ“ Created %d visualizations", n_plots))
```

```{r}
# ========================================================================
# 7.5 è¿½åŠ åˆ†æï¼šROCã‚«ãƒ¼ãƒ–ã€DCAã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ========================================================================

message("\n========================================")
message("ADDITIONAL ANALYSIS AND VISUALIZATIONS")
message("========================================\n")

# ã‚«ãƒ©ãƒ¼ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰å¯¾å¿œã®è‰²è¨­å®š
cb_palette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", 
                "#0072B2", "#D55E00", "#CC79A7", "#999999")

# ------------------------------------------------------------------------
# 1. ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨TNMãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
# ------------------------------------------------------------------------

message("1. Preparing models for comparison")
message("----------------------------------------")

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š
best_idx <- which.max(evaluation_results$summary$c_index_test)
best_model_name <- evaluation_results$summary$model[best_idx]
best_model <- models[[best_model_name]]

message(sprintf("Best model: %s (C-index = %.3f)", 
               best_model_name, 
               evaluation_results$summary$c_index_test[best_idx]))

# TNMãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
message("\nBuilding TNM reference model...")
tnm_data <- split_data_fixed$train
tnm_formula <- as.formula("surv_obj ~ t + n + m")

tnm_model <- tryCatch({
  coxph(tnm_formula, data = tnm_data)
}, error = function(e) {
  message("  Note: Standard TNM variables not found, using stage_diag as proxy")
  if ("stage_diag" %in% names(tnm_data)) {
    coxph(surv_obj ~ stage_diag, data = tnm_data)
  } else {
    NULL
  }
})

if (!is.null(tnm_model)) {
  tnm_c_index <- concordance(tnm_model)$concordance
  message(sprintf("TNM model C-index (train): %.3f", tnm_c_index))
}

# ------------------------------------------------------------------------
# 2. ROCã‚«ãƒ¼ãƒ–ä½œæˆï¼ˆå…¨ãƒ¢ãƒ‡ãƒ«ï¼‰
# ------------------------------------------------------------------------

message("\n2. Creating ROC curves for all models")
message("----------------------------------------")

# ROCä½œæˆé–¢æ•°
create_roc_curves_complete <- function(models, data, time_point = 24, output_file = NULL) {
  
  require(timeROC)
  require(pROC)
  
  # çµæœæ ¼ç´ç”¨
  all_roc_data <- list()
  all_auc_values <- list()
  
  # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
  model_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", 
                    "#0072B2", "#D55E00", "#CC79A7", "#999999", "#000000")
  
  # å„ãƒ¢ãƒ‡ãƒ«ã®ROCè¨ˆç®—
  model_idx <- 0
  
  for (model_name in names(models)) {
    model <- models[[model_name]]
    model_idx <- model_idx + 1
    
    if (!is.null(model)) {
      message(sprintf("  Processing: %s", model_name))
      
      # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’å–å¾—
      risk_score <- tryCatch({
        if (inherits(model, "coxph")) {
          predict(model, newdata = data, type = "lp")
        } else if (inherits(model, "list") && "model" %in% names(model) && !is.null(model$model)) {
          predict(model$model, newdata = data, type = "lp")
        } else {
          NULL
        }
      }, error = function(e) {
        NULL
      })
      
      if (!is.null(risk_score) && length(risk_score) == nrow(data)) {
        
        # pROCã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰
        tryCatch({
          outcome_binary <- as.numeric(data$recur_2y == TRUE & data$time2y <= time_point)
          
          if (sum(outcome_binary) > 0 && sum(outcome_binary) < length(outcome_binary)) {
            roc_obj <- pROC::roc(outcome_binary, risk_score, quiet = TRUE)
            coords_all <- coords(roc_obj, "all", ret = c("specificity", "sensitivity"))
            
            all_roc_data[[model_name]] <- data.frame(
              model = model_name,
              FPR = 1 - coords_all$specificity,
              TPR = coords_all$sensitivity
            )
            
            all_auc_values[[model_name]] <- as.numeric(auc(roc_obj))
            message(sprintf("    AUC: %.3f", all_auc_values[[model_name]]))
          }
        }, error = function(e) {
          message(sprintf("    Error: %s", e$message))
        })
      }
    }
  }
  
  # TNMãƒ¢ãƒ‡ãƒ«ã‚‚è¿½åŠ 
  if (exists("tnm_model") && !is.null(tnm_model)) {
    message("  Processing: TNM Model")
    
    tnm_risk <- predict(tnm_model, newdata = data, type = "lp")
    outcome_binary <- as.numeric(data$recur_2y == TRUE & data$time2y <= time_point)
    
    if (sum(outcome_binary) > 0) {
      roc_tnm <- pROC::roc(outcome_binary, tnm_risk, quiet = TRUE)
      coords_tnm <- coords(roc_tnm, "all", ret = c("specificity", "sensitivity"))
      
      all_roc_data[["TNM Model"]] <- data.frame(
        model = "TNM Model",
        FPR = 1 - coords_tnm$specificity,
        TPR = coords_tnm$sensitivity
      )
      
      all_auc_values[["TNM Model"]] <- as.numeric(auc(roc_tnm))
      message(sprintf("    TNM AUC: %.3f", all_auc_values[["TNM Model"]]))
    }
  }
  
  # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
  if (length(all_roc_data) > 0) {
    roc_data_combined <- do.call(rbind, all_roc_data)
    
    # AUCãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    auc_df <- data.frame(
      model = names(all_auc_values),
      AUC = unlist(all_auc_values),
      stringsAsFactors = FALSE
    )
    
    # AUCã§ã‚½ãƒ¼ãƒˆ
    auc_df <- auc_df[order(auc_df$AUC, decreasing = TRUE), ]
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    p <- ggplot(roc_data_combined, aes(x = FPR, y = TPR, color = model)) +
      geom_line(size = 1.2, alpha = 0.9) +
      geom_abline(intercept = 0, slope = 1, linetype = "dashed", 
                  color = "gray50", size = 0.8) +
      scale_color_manual(
        values = setNames(model_colors[1:length(unique(roc_data_combined$model))], 
                         auc_df$model),
        labels = paste0(auc_df$model, " (AUC = ", sprintf("%.3f", auc_df$AUC), ")"),
        breaks = auc_df$model
      ) +
      labs(
        title = sprintf("ROC Curves at %d Months", time_point),
        subtitle = sprintf("Best: %s (AUC = %.3f)", auc_df$model[1], auc_df$AUC[1]),
        x = "False Positive Rate (1 - Specificity)",
        y = "True Positive Rate (Sensitivity)",
        color = "Model"
      ) +
      theme_minimal(base_size = 11) +
      theme(
        legend.position = "right",
        legend.text = element_text(size = 9),
        panel.grid.minor = element_blank()
      ) +
      coord_equal() +
      xlim(0, 1) + ylim(0, 1)
    
    if (!is.null(output_file)) {
      ggsave(output_file, plot = p, width = 10, height = 8, dpi = 300)
      message(sprintf("\nâœ“ ROC plot saved to: %s", basename(output_file)))
    }
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ä¿å­˜
    assign("roc_data_all", roc_data_combined, envir = .GlobalEnv)
    assign("auc_values", auc_df, envir = .GlobalEnv)
    
    return(p)
  } else {
    return(NULL)
  }
}

# ROCãƒ—ãƒ­ãƒƒãƒˆå®Ÿè¡Œ
roc_plot_final <- create_roc_curves_complete(
  models = models,
  data = split_data_fixed$test,
  time_point = 24,
  output_file = file.path(paths$output_figures, "roc_curves_all_models.pdf")
)

# ------------------------------------------------------------------------
# 3. Decision Curve Analysis (DCA)
# ------------------------------------------------------------------------

message("\n3. Creating Decision Curve Analysis")
message("----------------------------------------")

perform_dca_fixed <- function(models, data, time_point = 24, output_file = NULL) {
  
  # é–¾å€¤ã®ç¯„å›²
  thresholds <- seq(0.01, 0.50, by = 0.01)
  dca_results <- data.frame()
  
  # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
  model_list <- list(
    "Best Model" = best_model,
    "TNM Model" = tnm_model
  )
  
  for (model_name in names(model_list)) {
    model <- model_list[[model_name]]
    
    if (!is.null(model)) {
      # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‹ã‚‰äºˆæ¸¬ç¢ºç‡ã‚’è¨ˆç®—
      if (inherits(model, "coxph")) {
        lp <- predict(model, newdata = data, type = "lp")
        surv_obj <- survfit(model, newdata = data[1,])
        time_idx <- which.min(abs(surv_obj$time - time_point))
        baseline_surv <- surv_obj$surv[time_idx]
        pred_prob <- 1 - baseline_surv^exp(lp)
      } else {
        next
      }
      
      # å®Ÿéš›ã®ã‚¤ãƒ™ãƒ³ãƒˆ
      event_occurred <- (data$recur_2y == TRUE) & (data$time2y <= time_point)
      
      # å„é–¾å€¤ã§ã®Net Benefitè¨ˆç®—
      for (thresh in thresholds) {
        treat <- pred_prob >= thresh
        tp <- sum(treat & event_occurred, na.rm = TRUE)
        fp <- sum(treat & !event_occurred, na.rm = TRUE)
        n <- length(event_occurred)
        
        net_benefit <- (tp/n) - (fp/n) * (thresh/(1-thresh))
        
        dca_results <- rbind(dca_results, data.frame(
          model = model_name,
          threshold = thresh,
          net_benefit = net_benefit
        ))
      }
    }
  }
  
  # Treat All/None ã®è¿½åŠ 
  event_rate <- mean((data$recur_2y == TRUE) & (data$time2y <= time_point))
  
  for (thresh in thresholds) {
    # Treat All
    net_benefit_all <- event_rate - (1-event_rate) * (thresh/(1-thresh))
    dca_results <- rbind(dca_results, data.frame(
      model = "Treat All",
      threshold = thresh,
      net_benefit = net_benefit_all
    ))
    
    # Treat None
    dca_results <- rbind(dca_results, data.frame(
      model = "Treat None", 
      threshold = thresh,
      net_benefit = 0
    ))
  }
  
  # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
  p <- ggplot(dca_results, aes(x = threshold, y = net_benefit, color = model)) +
    geom_line(size = 1.2) +
    scale_color_manual(values = c(
      "Best Model" = cb_palette[1],
      "TNM Model" = cb_palette[2],
      "Treat All" = "gray60",
      "Treat None" = "gray80"
    )) +
    scale_x_continuous(limits = c(0, 0.5), breaks = seq(0, 0.5, 0.1)) +
    labs(
      title = "Decision Curve Analysis",
      subtitle = sprintf("Net benefit at %d months", time_point),
      x = "Threshold Probability",
      y = "Net Benefit",
      color = "Strategy"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      legend.position = "bottom",
      panel.grid.minor = element_blank()
    ) +
    geom_hline(yintercept = 0, linetype = "dotted", color = "black")
  
  if (!is.null(output_file)) {
    ggsave(output_file, plot = p, width = 10, height = 8, dpi = 300)
    message(sprintf("  âœ“ DCA plot saved to: %s", basename(output_file)))
  }
  
  return(p)
}

# DCAãƒ—ãƒ­ãƒƒãƒˆå®Ÿè¡Œ
dca_plot <- perform_dca_fixed(
  models = models,
  data = split_data_fixed$test,
  time_point = 24,
  output_file = file.path(paths$output_figures, "dca_comparison.pdf")
)

# ------------------------------------------------------------------------
# 4. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
# ------------------------------------------------------------------------

message("\n4. Calibration Assessment")
message("----------------------------------------")

assess_calibration_robust <- function(model, data, time_point = 24, n_groups = 10) {
  
  # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‹ã‚‰äºˆæ¸¬ç¢ºç‡ã‚’è¨ˆç®—
  if (inherits(model, "coxph")) {
    lp <- predict(model, newdata = data, type = "lp")
  } else if (inherits(model, "list") && "model" %in% names(model)) {
    model <- model$model
    lp <- predict(model, newdata = data, type = "lp")
  } else {
    return(NULL)
  }
  
  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒã‚¶ãƒ¼ãƒ‰ã‚’ä½¿ã£ãŸäºˆæ¸¬ç¢ºç‡ã®è¨ˆç®—
  basehaz_df <- basehaz(model, centered = FALSE)
  time_idx <- which.min(abs(basehaz_df$time - time_point))
  
  if (length(time_idx) == 0) {
    time_idx <- nrow(basehaz_df)
  }
  
  baseline_cumhaz <- basehaz_df$hazard[time_idx]
  pred_prob <- 1 - exp(-baseline_cumhaz * exp(lp))
  
  # äºˆæ¸¬ç¢ºç‡ãŒæœ‰åŠ¹ã‹ç¢ºèª
  if (all(is.na(pred_prob)) || length(unique(pred_prob)) < 3) {
    message("  Warning: Insufficient variation in predicted probabilities")
    return(NULL)
  }
  
  # ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²
  if (length(unique(pred_prob)) >= n_groups) {
    pred_groups <- cut(pred_prob, 
                      breaks = quantile(pred_prob, probs = seq(0, 1, length.out = n_groups + 1)),
                      include.lowest = TRUE,
                      labels = FALSE)
  } else {
    n_groups <- min(5, length(unique(pred_prob)))
    pred_groups <- cut(pred_prob, 
                      breaks = n_groups,
                      include.lowest = TRUE,
                      labels = FALSE)
  }
  
  # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®è¦³å¯Ÿãƒ»æœŸå¾…ã‚¤ãƒ™ãƒ³ãƒˆç‡
  calibration_data <- data.frame()
  
  for (g in 1:n_groups) {
    idx <- which(pred_groups == g)
    
    if (length(idx) >= 3) {
      events_in_group <- sum(data$recur_2y[idx] == TRUE & data$time2y[idx] <= time_point)
      total_in_group <- length(idx)
      observed <- events_in_group / total_in_group
      expected <- mean(pred_prob[idx])
      
      calibration_data <- rbind(calibration_data, data.frame(
        group = g,
        n = length(idx),
        expected = expected,
        observed = observed,
        events = events_in_group
      ))
    }
  }
  
  # Calibration-in-the-large ã¨ Calibration slope
  if (nrow(calibration_data) > 2) {
    cal_model <- tryCatch({
      lm(observed ~ expected, data = calibration_data, weights = n)
    }, error = function(e) {
      lm(observed ~ expected, data = calibration_data)
    })
    
    calibration_slope <- coef(cal_model)[2]
    calibration_intercept <- coef(cal_model)[1]
  } else {
    calibration_slope <- NA
    calibration_intercept <- NA
  }
  
  return(list(
    data = calibration_data,
    slope = calibration_slope,
    intercept = calibration_intercept
  ))
}

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
best_calibration <- assess_calibration_robust(
  model = best_model,
  data = split_data_fixed$test,
  time_point = 24
)

if (!is.null(best_calibration)) {
  message(sprintf("\nBest Model Calibration:"))
  message(sprintf("  Calibration-in-the-large (intercept): %.3f", 
                 ifelse(is.na(best_calibration$intercept), NA, best_calibration$intercept)))
  message(sprintf("  Calibration slope: %.3f", 
                 ifelse(is.na(best_calibration$slope), NA, best_calibration$slope)))
  
  if (!is.na(best_calibration$slope)) {
    interpretation <- ifelse(
      abs(best_calibration$slope - 1) < 0.2, 
      "Good calibration",
      ifelse(best_calibration$slope < 0.8, 
             "Overfitting tendency", 
             ifelse(best_calibration$slope > 1.2,
                    "Underfitting tendency",
                    "Acceptable calibration"))
    )
    message(sprintf("  Interpretation: %s", interpretation))
  }
}

# ------------------------------------------------------------------------
# 5. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒƒãƒˆ
# ------------------------------------------------------------------------

message("\n5. Creating Calibration Plot")
message("----------------------------------------")

if (!is.null(best_calibration) && nrow(best_calibration$data) > 0) {
  
  cal_data <- best_calibration$data
  
  # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
  cal_plot <- ggplot(cal_data, aes(x = expected, y = observed)) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray50", size = 1) +
    {if(nrow(cal_data) >= 3) 
      geom_smooth(method = "lm", se = TRUE, color = cb_palette[1], fill = cb_palette[1], alpha = 0.2)
    } +
    geom_point(aes(size = n), color = cb_palette[2], alpha = 0.7) +
    geom_errorbar(
      aes(ymin = observed - 1.96*sqrt(observed*(1-observed)/n),
          ymax = observed + 1.96*sqrt(observed*(1-observed)/n)),
      width = 0.02, color = cb_palette[2], alpha = 0.5
    ) +
    labs(
      title = sprintf("Calibration Plot - %s", best_model_name),
      subtitle = sprintf("Calibration slope = %.3f, Intercept = %.3f",
                        ifelse(is.na(best_calibration$slope), NA, best_calibration$slope),
                        ifelse(is.na(best_calibration$intercept), NA, best_calibration$intercept)),
      x = "Expected Event Probability",
      y = "Observed Event Probability",
      size = "Sample Size"
    ) +
    scale_x_continuous(limits = c(0, 1), labels = scales::percent) +
    scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
    theme_minimal(base_size = 12) +
    theme(
      legend.position = "bottom",
      panel.grid.minor = element_blank()
    ) +
    coord_equal()
  
  # ä¿å­˜
  ggsave(
    file.path(paths$output_figures, "calibration_plot.pdf"),
    plot = cal_plot,
    width = 8,
    height = 8,
    dpi = 300
  )
  message("  âœ“ Calibration plot saved")
  
} else {
  message("  âš  Calibration plot could not be created due to insufficient data")
  cal_plot <- NULL
}

# ------------------------------------------------------------------------
# 6. çµ±åˆå›³ã®ä½œæˆ
# ------------------------------------------------------------------------

message("\n6. Creating Combined Figure")
message("----------------------------------------")

if (!is.null(roc_plot_final) && !is.null(dca_plot) && !is.null(cal_plot)) {
  library(patchwork)
  
  combined_plot <- (roc_plot_final + dca_plot) / cal_plot +
    plot_annotation(
      title = "Model Performance Evaluation",
      subtitle = sprintf("Best Model: %s", best_model_name),
      theme = theme(plot.title = element_text(size = 16, face = "bold"))
    )
  
  ggsave(
    file.path(paths$output_figures, "combined_evaluation.pdf"),
    plot = combined_plot,
    width = 16,
    height = 16,
    dpi = 300
  )
  message("  âœ“ Combined evaluation plot saved")
}

# ------------------------------------------------------------------------
# 7. è¿½åŠ åˆ†æã‚µãƒãƒªãƒ¼
# ------------------------------------------------------------------------

message("\n========================================")
message("ADDITIONAL ANALYSIS COMPLETE")
message("========================================\n")

message("ğŸ“Š Summary of Additional Analysis:")
message(sprintf("  Best Model: %s", best_model_name))
message(sprintf("  C-index (test): %.3f", evaluation_results$summary$c_index_test[best_idx]))

if (!is.null(tnm_model)) {
  tnm_test_pred <- predict(tnm_model, newdata = split_data_fixed$test, type = "risk")
  tnm_test_c <- concordance(split_data_fixed$test$surv_obj ~ tnm_test_pred, reverse = TRUE)$concordance
  message(sprintf("  TNM Model C-index (test): %.3f", tnm_test_c))
  message(sprintf("  Improvement over TNM: +%.3f", 
                 evaluation_results$summary$c_index_test[best_idx] - tnm_test_c))
}

if (!is.null(best_calibration)) {
  message(sprintf("\n  Calibration Assessment:"))
  message(sprintf("    Calibration-in-the-large: %.3f", best_calibration$intercept))
  message(sprintf("    Calibration slope: %.3f", best_calibration$slope))
}

# è¿½åŠ åˆ†æçµæœã®ä¿å­˜
additional_results <- list(
  best_model_name = best_model_name,
  best_model = best_model,
  tnm_model = tnm_model,
  tnm_comparison = ifelse(exists("tnm_test_c"), tnm_test_c, NA),
  calibration = best_calibration,
  roc_auc_values = if(exists("auc_values")) auc_values else NULL
)

saveRDS(additional_results, 
        file.path(paths$output_models, "additional_analysis_results.rds"))

message("\nâœ… Additional analysis results saved!")
```

```{r}
# ========================================================================
# ROCã‚«ãƒ¼ãƒ–ä½œæˆé–¢æ•°ã®ä¿®æ­£ç‰ˆï¼ˆLASSOå¯¾å¿œï¼‰
# ========================================================================

message("\n========================================")
message("FIXING ROC CALCULATION FOR LASSO MODELS")
message("========================================\n")

# ä¿®æ­£ç‰ˆï¼šLASSOãƒ¢ãƒ‡ãƒ«å¯¾å¿œã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—é–¢æ•°
get_risk_score_fixed <- function(model, data) {
  
  # Coxphãƒ¢ãƒ‡ãƒ«
  if (inherits(model, "coxph")) {
    return(predict(model, newdata = data, type = "lp"))
  }
  
  # ãƒªã‚¹ãƒˆå‹ã§coxphã‚’å«ã‚€å ´åˆ
  else if (inherits(model, "list") && "model" %in% names(model) && 
           !is.null(model$model) && inherits(model$model, "coxph")) {
    return(predict(model$model, newdata = data, type = "lp"))
  }
  
  # LASSOãƒ¢ãƒ‡ãƒ«ï¼ˆMethod 2: glmnetç›´æ¥ä½¿ç”¨ï¼‰
  else if (inherits(model, "lasso_cox") || 
           (!is.null(model$glmnet_model) && !is.null(model$X))) {
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”¨ã®è¡Œåˆ—ã‚’ä½œæˆ
    X_test <- matrix(0, nrow = nrow(data), ncol = ncol(model$X))
    colnames(X_test) <- colnames(model$X)
    
    # åˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ã‚’ãƒãƒƒãƒãƒ³ã‚°
    common_vars <- intersect(colnames(model$X), names(data))
    
    for (var in common_vars) {
      if (var %in% names(data)) {
        # æ•°å€¤ã«å¤‰æ›ï¼ˆå› å­å¤‰æ•°ã®å ´åˆã‚‚è€ƒæ…®ï¼‰
        if (is.factor(data[[var]])) {
          X_test[, var] <- as.numeric(data[[var]]) - 1  # 0/1ã«å¤‰æ›
        } else {
          X_test[, var] <- as.numeric(data[[var]])
        }
      }
    }
    
    # äºˆæ¸¬
    pred <- predict(model$glmnet_model, 
                   newx = X_test, 
                   s = model$lambda_min, 
                   type = "link")
    
    return(as.numeric(pred))
  }
  
  # ãã®ä»–ã®å ´åˆ
  else {
    return(NULL)
  }
}

# ROCä½œæˆé–¢æ•°ã‚’æ›´æ–°ï¼ˆLASSOå¯¾å¿œç‰ˆï¼‰
create_roc_curves_complete_v2 <- function(models, data, time_point = 24, output_file = NULL) {
  
  require(pROC)
  
  # çµæœæ ¼ç´ç”¨
  all_roc_data <- list()
  all_auc_values <- list()
  
  # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
  model_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", 
                    "#0072B2", "#D55E00", "#CC79A7", "#999999", "#000000")
  
  # å„ãƒ¢ãƒ‡ãƒ«ã®ROCè¨ˆç®—
  model_idx <- 0
  
  for (model_name in names(models)) {
    model <- models[[model_name]]
    model_idx <- model_idx + 1
    
    if (!is.null(model)) {
      message(sprintf("Processing: %s", model_name))
      
      # ä¿®æ­£ç‰ˆã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢å–å¾—
      risk_score <- get_risk_score_fixed(model, data)
      
      if (!is.null(risk_score) && length(risk_score) == nrow(data)) {
        
        # ãƒã‚¤ãƒŠãƒªã‚¢ã‚¦ãƒˆã‚«ãƒ 
        outcome_binary <- as.numeric(data$recur_2y == TRUE & data$time2y <= time_point)
        
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        valid_idx <- !is.na(risk_score) & !is.na(outcome_binary)
        
        if (sum(valid_idx) > 10 && sum(outcome_binary[valid_idx]) > 0) {
          
          # pROCã§ROCè¨ˆç®—
          tryCatch({
            roc_obj <- pROC::roc(outcome_binary[valid_idx], 
                                risk_score[valid_idx], 
                                quiet = TRUE)
            coords_all <- coords(roc_obj, "all", ret = c("specificity", "sensitivity"))
            
            all_roc_data[[model_name]] <- data.frame(
              model = model_name,
              FPR = 1 - coords_all$specificity,
              TPR = coords_all$sensitivity
            )
            
            all_auc_values[[model_name]] <- as.numeric(auc(roc_obj))
            message(sprintf("  AUC: %.3f", all_auc_values[[model_name]]))
            
          }, error = function(e) {
            message(sprintf("  Error: %s", e$message))
          })
        }
      } else {
        message(sprintf("  Risk score calculation failed"))
      }
    }
  }
  
  # TNMãƒ¢ãƒ‡ãƒ«ã‚‚è¿½åŠ 
  if (exists("tnm_model") && !is.null(tnm_model)) {
    message("Processing: TNM Model")
    
    tnm_risk <- get_risk_score_fixed(tnm_model, data)
    
    if (!is.null(tnm_risk)) {
      outcome_binary <- as.numeric(data$recur_2y == TRUE & data$time2y <= time_point)
      
      roc_tnm <- pROC::roc(outcome_binary, tnm_risk, quiet = TRUE)
      coords_tnm <- coords(roc_tnm, "all", ret = c("specificity", "sensitivity"))
      
      all_roc_data[["TNM Model"]] <- data.frame(
        model = "TNM Model",
        FPR = 1 - coords_tnm$specificity,
        TPR = coords_tnm$sensitivity
      )
      
      all_auc_values[["TNM Model"]] <- as.numeric(auc(roc_tnm))
      message(sprintf("  TNM AUC: %.3f", all_auc_values[["TNM Model"]]))
    }
  }
  
  # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ
  if (length(all_roc_data) > 0) {
    roc_data_combined <- do.call(rbind, all_roc_data)
    
    # AUCãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    auc_df <- data.frame(
      model = names(all_auc_values),
      AUC = unlist(all_auc_values),
      stringsAsFactors = FALSE
    )
    
    # AUCã§ã‚½ãƒ¼ãƒˆ
    auc_df <- auc_df[order(auc_df$AUC, decreasing = TRUE), ]
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    p <- ggplot(roc_data_combined, aes(x = FPR, y = TPR, color = model)) +
      geom_line(size = 1.2, alpha = 0.9) +
      geom_abline(intercept = 0, slope = 1, linetype = "dashed", 
                  color = "gray50", size = 0.8) +
      scale_color_manual(
        values = setNames(model_colors[1:length(unique(roc_data_combined$model))], 
                         auc_df$model),
        labels = paste0(auc_df$model, " (AUC = ", sprintf("%.3f", auc_df$AUC), ")"),
        breaks = auc_df$model
      ) +
      labs(
        title = sprintf("ROC Curves at %d Months - All Models", time_point),
        subtitle = sprintf("Best: %s (AUC = %.3f)", auc_df$model[1], auc_df$AUC[1]),
        x = "False Positive Rate (1 - Specificity)",
        y = "True Positive Rate (Sensitivity)",
        color = "Model"
      ) +
      theme_minimal(base_size = 11) +
      theme(
        legend.position = "right",
        legend.text = element_text(size = 9),
        panel.grid.minor = element_blank()
      ) +
      coord_equal() +
      xlim(0, 1) + ylim(0, 1)
    
    if (!is.null(output_file)) {
      ggsave(output_file, plot = p, width = 10, height = 8, dpi = 300)
      message(sprintf("\nâœ“ ROC plot saved to: %s", basename(output_file)))
    }
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
    assign("roc_data_all", roc_data_combined, envir = .GlobalEnv)
    assign("auc_values", auc_df, envir = .GlobalEnv)
    
    return(p)
  } else {
    return(NULL)
  }
}

# ä¿®æ­£ç‰ˆã§å†å®Ÿè¡Œ
message("\nRe-running ROC with fixed LASSO support...")
roc_plot_fixed <- create_roc_curves_complete_v2(
  models = models,
  data = split_data_fixed$test,
  time_point = 24,
  output_file = file.path(paths$output_figures, "roc_curves_all_models_fixed.pdf")
)

# ç¢ºèª
if (!is.null(roc_plot_fixed)) {
  print(roc_plot_fixed)
  
  # AUCå€¤ã®ç¢ºèª
  message("\nğŸ“Š Updated AUC values:")
  print(auc_values)
  
  # Model Performanceè¡¨ã‚‚æ›´æ–°
  message("\nUpdating performance table with correct AUC values...")
  
  # æ—¢å­˜ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
  if (exists("comprehensive_performance")) {
    for (i in 1:nrow(comprehensive_performance)) {
      model_name <- comprehensive_performance$Model[i]
      if (model_name %in% auc_values$model) {
        idx <- which(auc_values$model == model_name)
        comprehensive_performance[i, "AUC at 24mo"] <- auc_values$AUC[idx]
      }
    }
    
    # å†ä¿å­˜
    write.csv(
      comprehensive_performance,
      file.path(paths$output_tables, "model_performance_comprehensive_fixed.csv"),
      row.names = FALSE
    )
    
    message("âœ“ Updated performance table saved")
  }
}

message("\nâœ… LASSO AUC issue fixed!")
```


```{r}
# ========================================================================
# 8. çµæœã‚µãƒãƒªãƒ¼ï¼ˆè¿½åŠ åˆ†æã‚’å«ã‚€æ›´æ–°ç‰ˆï¼‰
# ========================================================================

message("\n")
message("================================================================================")
message("                              Pipeline Completed                                ")
message("================================================================================")

# å®Ÿè¡Œæ™‚é–“
end_time <- Sys.time()
elapsed_time <- difftime(end_time, start_time, units = "mins")

message(sprintf("\nExecution Summary:"))
message(sprintf("  Total time: %.1f minutes", as.numeric(elapsed_time)))
message(sprintf("  Data: %d samples (%d train, %d val, %d test)",
               nrow(final_data),
               nrow(split_data$train),
               nrow(split_data$val),
               nrow(split_data$test)))
message(sprintf("  Models built: %d", n_successful))
message(sprintf("  Output directory: %s", paths$output))

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è©³ç´°è¡¨ç¤ºï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãã®ã¾ã¾ï¼‰
if (exists("evaluation_results") && !is.null(evaluation_results$summary)) {
  best_idx <- which.max(evaluation_results$summary$c_index_test)
  if (length(best_idx) > 0) {
    best <- evaluation_results$summary[best_idx, ]
    message(sprintf("\nğŸ† BEST MODEL: %s", best$model))
    message(sprintf("  C-index (Train/Val/Test): %.3f / %.3f / %.3f",
                   best$c_index_train, best$c_index_val, best$c_index_test))
    
    # TNMã¨ã®æ¯”è¼ƒï¼ˆè¿½åŠ ï¼‰
    if (exists("additional_results") && !is.null(additional_results$tnm_comparison)) {
      message(sprintf("  TNM C-index: %.3f", additional_results$tnm_comparison))
      message(sprintf("  Improvement over TNM: +%.3f", 
                     best$c_index_test - additional_results$tnm_comparison))
    }
    
    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®å¤‰æ•°ã‚’è¡¨ç¤º
    best_model <- models[[best$model]]
    if (!is.null(best_model)) {
      if (inherits(best_model, "coxph")) {
        vars <- names(coef(best_model))
      } else if (inherits(best_model, "list") && "selected_vars" %in% names(best_model)) {
        vars <- best_model$selected_vars
      } else {
        vars <- NULL
      }
      
      if (!is.null(vars)) {
        message(sprintf("  Variables (%d): %s", 
                       length(vars),
                       paste(vars, collapse = ", ")))
      }
    }
  }
}

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆè¿½åŠ åˆ†æã‚’å«ã‚€æ›´æ–°ç‰ˆï¼‰
message("\nGenerated Files:")
output_files <- list(
  "ğŸ“Š Data" = file.path(paths$output, "processed_data.rds"),
  "ğŸ”€ Split" = file.path(paths$output_models, "data_split.rds"),
  "ğŸ¤– Models" = file.path(paths$output_models, "all_models.rds"),
  "ğŸ“ˆ Evaluation" = file.path(paths$output_models, "evaluation_results.rds"),
  "ğŸ”¬ Additional Analysis" = file.path(paths$output_models, "additional_analysis_results.rds"),
  "ğŸ“‹ Summary Table" = file.path(paths$output_tables, "model_performance.csv"),
  "ğŸ“‰ ROC Curves" = file.path(paths$output_figures, "roc_curves_all_models.pdf"),
  "ğŸ“Š DCA" = file.path(paths$output_figures, "dca_comparison.pdf"),
  "ğŸ¯ Calibration" = file.path(paths$output_figures, "calibration_plot.pdf"),
  "ğŸ¨ Combined Plot" = file.path(paths$output_figures, "combined_evaluation.pdf")
)

for (name in names(output_files)) {
  if (file.exists(output_files[[name]]) || dir.exists(output_files[[name]])) {
    message(sprintf("  %s: %s", name, basename(output_files[[name]])))
  }
}

message("\nâœ… All tasks completed successfully!")
message(sprintf("\nğŸ‰ Results are available in: %s", paths$output))
message("\nNext steps:")
message("  1. Review model performance in: 03_Output/tables/model_performance.csv")
message("  2. Check ROC curves in: 03_Output/figures/roc_curves_all_models.pdf")
message("  3. Check DCA in: 03_Output/figures/dca_comparison.pdf")
message("  4. Check calibration in: 03_Output/figures/calibration_plot.pdf")
message("  5. Load best model with: readRDS('03_Output/models/all_models.rds')")

message("\n================================================================================\n")
```



```{r}
# ========================================================================
# 9. ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
# ========================================================================

if (!is.null(config$output$report$generate) && config$output$report$generate) {
  message("\nğŸ“ Generating report...")
  message("----------------------------------------")
  
  # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒã‚ã‚Œã°å®Ÿè¡Œ
  report_script <- file.path(script_dir, "report_generator.R")
  if (file.exists(report_script)) {
    source(report_script)
    
    generate_report(
      evaluation_results = evaluation_results,
      models = models,
      config = config,
      output_dir = paths$output_reports
    )
  } else {
    message("  Report generator not found. Skipping report generation.")
  }
}
```



```{r}
# ========================================================================
# 10. æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# ========================================================================

message("\nâœ… All tasks completed successfully!")
message(sprintf("\nğŸ‰ Results are available in: %s", paths$output))
message("\nNext steps:")
message("  1. Review model performance in: 03_Output/tables/model_performance.csv")
message("  2. Check visualizations in: 03_Output/figures/")
message("  3. Load best model with: readRDS('03_Output/models/all_models.rds')")

# ========================================================================
# 11. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# ========================================================================

# ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
if (!is.null(config$runtime$clean_workspace) && config$runtime$clean_workspace) {
  message("\nğŸ§¹ Cleaning workspace...")
  
  # é‡è¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ä¿æŒ
  keep_objects <- c("evaluation_results", "models", "final_data", "config", "paths")
  rm_objects <- setdiff(ls(), keep_objects)
  
  if (length(rm_objects) > 0) {
    rm(list = rm_objects)
    message(sprintf("  Removed %d temporary objects", length(rm_objects)))
  }
  
  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
  gc(verbose = FALSE)
  message("  âœ“ Memory cleaned")
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®ä¿å­˜
session_file <- file.path(paths$output, 
                         sprintf("session_info_%s.txt", 
                                format(Sys.Date(), "%Y%m%d")))
sink(session_file)
cat("=== Session Information ===\n")
cat("Date:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("Execution time:", sprintf("%.1f minutes", as.numeric(elapsed_time)), "\n\n")
print(sessionInfo())
sink()

message(sprintf("\nğŸ“„ Session info saved to: %s", basename(session_file)))
message("\n================================================================================\n")
```

```{r}
# ========================================================================
# Table 1: æ‚£è€…èƒŒæ™¯ã®ä½œæˆ
# ========================================================================

message("\n========================================")
message("Creating Table 1: Baseline Characteristics")
message("========================================\n")

create_table1 <- function(data_list, output_file = NULL) {
  require(tableone)
  require(dplyr)
  
  # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆå…¨ä½“ç”¨ï¼‰
  all_data <- rbind(
    cbind(data_list$train, dataset = "Train"),
    cbind(data_list$val, dataset = "Validation"),
    cbind(data_list$test, dataset = "Test")
  )
  all_data$dataset <- factor(all_data$dataset, levels = c("Train", "Validation", "Test"))
  
  # Table 1ç”¨ã®å¤‰æ•°ã‚’é¸æŠ
  vars_continuous <- c(
    "age", "alb", "tbil", "ast", "alt", "plt", 
    "pt_inr", "afp", "pivka2", "max_diam_cm", "count",
    "ALBIscore", "BMI", "icg_r15"
  )
  
  vars_categorical <- c(
    "sex", "hbv", "child_pugh", "liver_damage", 
    "stage_diag", "ALBIgrade", "microVI", "macroVI",
    "fc", "fc_inf", "sm", "t", "n", "m"
  )
  
  # åˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ã®ã¿é¸æŠ
  vars_continuous <- intersect(vars_continuous, names(all_data))
  vars_categorical <- intersect(vars_categorical, names(all_data))
  
  # ã™ã¹ã¦ã®å¤‰æ•°
  all_vars <- c(vars_continuous, vars_categorical)
  
  # ã‚¢ã‚¦ãƒˆã‚«ãƒ å¤‰æ•°
  outcome_vars <- c("recur_2y", "time2y")
  
  # å› å­å¤‰æ•°ã¨ã—ã¦æŒ‡å®š
  factor_vars <- vars_categorical
  
  # Table 1ã‚’ä½œæˆ
  table1 <- CreateTableOne(
    vars = c(all_vars, outcome_vars),
    strata = "dataset",
    data = all_data,
    factorVars = factor_vars,
    addOverall = TRUE
  )
  
  # è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  table1_print <- print(
    table1,
    nonnormal = vars_continuous,  # ä¸­å¤®å€¤ï¼ˆIQRï¼‰ã§è¡¨ç¤º
    quote = FALSE,
    noSpaces = TRUE,
    printToggle = FALSE,
    showAllLevels = TRUE,
    cramVars = c("stage_diag", "ALBIgrade"),  # ä¸€è¡Œã«ã¾ã¨ã‚ã‚‹
    test = TRUE,  # på€¤ã‚’è¨ˆç®—
    smd = TRUE    # SMDã‚‚è¨ˆç®—
  )
  
  # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
  table1_df <- as.data.frame(table1_print)
  table1_df$Variable <- rownames(table1_df)
  table1_df <- table1_df[, c("Variable", names(table1_df)[names(table1_df) != "Variable"])]
  rownames(table1_df) <- NULL
  
  # ã‚ˆã‚Šèª­ã¿ã‚„ã™ã„å¤‰æ•°åã«å¤‰æ›´
  var_labels <- c(
    "age" = "Age (years)",
    "sex" = "Sex",
    "alb" = "Albumin (g/dL)",
    "tbil" = "Total bilirubin (mg/dL)",
    "ast" = "AST (IU/L)",
    "alt" = "ALT (IU/L)",
    "plt" = "Platelet count (Ã—10â´/Î¼L)",
    "pt_inr" = "PT-INR",
    "afp" = "AFP (ng/mL)",
    "pivka2" = "PIVKA-II (mAU/mL)",
    "max_diam_cm" = "Maximum tumor diameter (cm)",
    "count" = "Number of tumors",
    "child_pugh" = "Child-Pugh class",
    "liver_damage" = "Liver damage grade",
    "stage_diag" = "Stage",
    "ALBIscore" = "ALBI score",
    "ALBIgrade" = "ALBI grade",
    "microVI" = "Microvascular invasion",
    "macroVI" = "Macrovascular invasion",
    "recur_2y" = "2-year recurrence",
    "time2y" = "Follow-up time (months)"
  )
  
  # å¤‰æ•°åã‚’ç½®æ›
  for (old_name in names(var_labels)) {
    table1_df$Variable <- gsub(paste0("^", old_name, "$"), 
                              var_labels[old_name], 
                              table1_df$Variable)
  }
  
  # CSVã¨ã—ã¦ä¿å­˜
  if (!is.null(output_file)) {
    write.csv(table1_df, output_file, row.names = FALSE)
    message(sprintf("âœ“ Table 1 saved to: %s", basename(output_file)))
  }
  
  return(table1_df)
}

# Table 1ã‚’ä½œæˆ
table1_result <- create_table1(
  data_list = split_data_fixed,
  output_file = file.path(paths$output_tables, "table1_baseline_characteristics.csv")
)

# è¡¨ç¤º
message("\nğŸ“‹ Table 1 Preview (first 20 rows):")
print(head(table1_result, 20))
```


```{r}
# ========================================================================
# Table 2: ãƒ¢ãƒ‡ãƒ«ä¿‚æ•°ã®è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
# ========================================================================

message("\n========================================")
message("Creating Table 2: Model Coefficients")
message("========================================\n")

create_table2 <- function(models, model_names = NULL, output_file = NULL) {
  
  # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒˆãƒƒãƒ—3ï¼‰
  if (is.null(model_names)) {
    # C-indexã§ãƒˆãƒƒãƒ—3ã‚’é¸æŠ
    if (exists("evaluation_results")) {
      top_models <- head(evaluation_results$summary[order(evaluation_results$summary$c_index_test, 
                                                          decreasing = TRUE), "model"], 3)
      model_names <- top_models
    } else {
      model_names <- names(models)[1:min(3, length(models))]
    }
  }
  
  # å„ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ã‚’æŠ½å‡º
  all_coef_tables <- list()
  
  for (model_name in model_names) {
    model <- models[[model_name]]
    
    if (!is.null(model)) {
      message(sprintf("Processing: %s", model_name))
      
      # Coxphãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
      if (inherits(model, "coxph")) {
        # ä¿‚æ•°ã¨ãã®çµ±è¨ˆé‡ã‚’å–å¾—
        model_summary <- summary(model)
        coef_table <- as.data.frame(model_summary$coefficients)
        conf_int <- as.data.frame(model_summary$conf.int)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        model_table <- data.frame(
          Model = model_name,
          Variable = rownames(coef_table),
          Beta = coef_table[, "coef"],
          SE = coef_table[, "se(coef)"],
          HR = conf_int[, "exp(coef)"],
          HR_Lower = conf_int[, "lower .95"],
          HR_Upper = conf_int[, "upper .95"],
          Z = coef_table[, "z"],
          P_value = coef_table[, "Pr(>|z|)"],
          stringsAsFactors = FALSE
        )
        
      } 
      # ãƒªã‚¹ãƒˆå‹ãƒ¢ãƒ‡ãƒ«ï¼ˆRFEã€Univariateç­‰ï¼‰ã®å ´åˆ
      else if (inherits(model, "list") && "model" %in% names(model) && !is.null(model$model)) {
        inner_model <- model$model
        
        if (inherits(inner_model, "coxph")) {
          model_summary <- summary(inner_model)
          coef_table <- as.data.frame(model_summary$coefficients)
          conf_int <- as.data.frame(model_summary$conf.int)
          
          model_table <- data.frame(
            Model = model_name,
            Variable = rownames(coef_table),
            Beta = coef_table[, "coef"],
            SE = coef_table[, "se(coef)"],
            HR = conf_int[, "exp(coef)"],
            HR_Lower = conf_int[, "lower .95"],
            HR_Upper = conf_int[, "upper .95"],
            Z = coef_table[, "z"],
            P_value = coef_table[, "Pr(>|z|)"],
            stringsAsFactors = FALSE
          )
        } else {
          next
        }
        
      }
      # LASSOãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
      else if (inherits(model, "lasso_cox")) {
        # LASSOã¯ä¿‚æ•°ã®ã¿ï¼ˆpå€¤ãªã—ï¼‰
        if (!is.null(model$selected_vars) && length(model$selected_vars) > 0) {
          # ç°¡æ˜“çš„ãªä¿‚æ•°è¡¨ç¤º
          model_table <- data.frame(
            Model = model_name,
            Variable = model$selected_vars,
            Beta = NA,  # LASSOã§ã¯å€‹åˆ¥ä¿‚æ•°ã‚’å–å¾—ã™ã‚‹ã®ãŒè¤‡é›‘
            SE = NA,
            HR = NA,
            HR_Lower = NA,
            HR_Upper = NA,
            Z = NA,
            P_value = NA,
            stringsAsFactors = FALSE
          )
          
          # æ³¨é‡ˆã‚’è¿½åŠ 
          model_table$Variable[1] <- paste0(model_table$Variable[1], " (LASSO selected)")
        } else {
          next
        }
      } else {
        next
      }
      
      # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
      all_coef_tables[[model_name]] <- model_table
    }
  }
  
  # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ã‚’çµåˆ
  if (length(all_coef_tables) > 0) {
    combined_table <- do.call(rbind, all_coef_tables)
    rownames(combined_table) <- NULL
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¿æ•´
    combined_table$Beta <- sprintf("%.3f", combined_table$Beta)
    combined_table$SE <- sprintf("%.3f", combined_table$SE)
    combined_table$HR <- sprintf("%.3f", combined_table$HR)
    combined_table$CI_95 <- sprintf("(%.3f-%.3f)", 
                                    combined_table$HR_Lower, 
                                    combined_table$HR_Upper)
    
    # På€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    combined_table$P_value_formatted <- ifelse(
      combined_table$P_value < 0.001, "<0.001",
      sprintf("%.3f", combined_table$P_value)
    )
    
    # æœ‰æ„æ€§ãƒãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ 
    combined_table$Significance <- ifelse(
      combined_table$P_value < 0.001, "***",
      ifelse(combined_table$P_value < 0.01, "**",
             ifelse(combined_table$P_value < 0.05, "*", ""))
    )
    
    # æœ€çµ‚çš„ãªãƒ†ãƒ¼ãƒ–ãƒ«
    final_table <- combined_table[, c("Model", "Variable", "Beta", "SE", 
                                      "HR", "CI_95", "P_value_formatted", "Significance")]
    
    names(final_table) <- c("Model", "Variable", "Î²", "SE", 
                            "HR", "95% CI", "P-value", "")
    
    # CSVã¨ã—ã¦ä¿å­˜
    if (!is.null(output_file)) {
      write.csv(final_table, output_file, row.names = FALSE)
      message(sprintf("âœ“ Table 2 saved to: %s", basename(output_file)))
    }
    
    return(final_table)
  } else {
    message("No valid models found for Table 2")
    return(NULL)
  }
}

# Table 2ã‚’ä½œæˆï¼ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨ãã®ä»–ã®ä¸»è¦ãƒ¢ãƒ‡ãƒ«ï¼‰
table2_result <- create_table2(
  models = models,
  model_names = c(best_model_name, "TNM Model"),  # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨TNMãƒ¢ãƒ‡ãƒ«
  output_file = file.path(paths$output_tables, "table2_model_coefficients.csv")
)

# è¡¨ç¤º
if (!is.null(table2_result)) {
  message("\nğŸ“‹ Table 2 Preview (first 20 rows):")
  print(head(table2_result, 20))
}

# Excelå½¢å¼ã§ã‚‚ä¿å­˜
if (require(openxlsx, quietly = TRUE)) {
  wb <- createWorkbook()
  
  # Table 1
  addWorksheet(wb, "Table 1 - Baseline")
  writeData(wb, "Table 1 - Baseline", table1_result)
  
  # Table 2
  if (!is.null(table2_result)) {
    addWorksheet(wb, "Table 2 - Coefficients")
    writeData(wb, "Table 2 - Coefficients", table2_result)
  }
  
  # ä¿å­˜
  saveWorkbook(wb, 
               file.path(paths$output_tables, "manuscript_tables.xlsx"),
               overwrite = TRUE)
  
  message("\nâœ“ Both tables saved to: manuscript_tables.xlsx")
}

message("\nâœ… Manuscript tables created successfully!")
```


