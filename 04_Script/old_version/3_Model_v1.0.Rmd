---
title: "Model"
author: "Takuto Yoshida"
date: "2025-10-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 準備
```{r}
## ==== CHUNK 0: Setup & Utils ====
req_pkgs <- c("tidyverse","survival","broom","glmnet","Matrix","lubridate")
to_install <- setdiff(req_pkgs, rownames(installed.packages()))
if(length(to_install)) install.packages(to_install, Ncpus = 2)
invisible(lapply(req_pkgs, library, character.only = TRUE))

stopifnot(exists("ds01_model"))

# 変数マッピング（必要に応じて右辺を実データ列に合わせてください）
var_map <- list(
  id          = "id",
  sex         = "sex",            # "M"/"F"
  alb_g_dl    = "alb",            # g/dL
  tbil_mg_dl  = "tbil",           # mg/dL
  afp_ng_ml   = "afp",            # ng/mL
  tum_diam_cm = "tum_diam_pre",   # cm（術前）
  tum_count   = "tum_count_pre",  # 個数（術前）
  time_months = "rfs_months",     # 月
  event_recur = "recur_tf",       # 1=再発, 0=打切り
  t_cat       = "t",
  n_cat       = "n",
  m_cat       = "m",
  vp_pre      = "vp_pre",
  vv_pre      = "vv_pre",
  vp_path     = "vp_path",
  vv_path     = "vv_path",
  op_date     = "op_date",        # Date
  group_rb    = "group_rb",
  stage_diag  = "stage_diag"
)

need_cols <- function(dat, vars){
  miss <- vars[!vars %in% names(dat)]
  if(length(miss)) stop("必要列が見つかりません: ", paste(miss, collapse=", "))
}

safe_ln <- function(x) ifelse(is.finite(x) & x > 0, log(x), NA_real_)

calc_albi <- function(alb_g_dl, tbil_mg_dl){
  alb_g_l   <- alb_g_dl * 10      # g/dL -> g/L
  tbil_umol <- tbil_mg_dl * 17.1  # mg/dL -> μmol/L
  score <- 0.66*log10(tbil_umol) - 0.085*alb_g_l
  grade <- dplyr::case_when(
    is.na(score)     ~ NA_integer_,
    score <= -2.60   ~ 1L,
    score <= -1.39   ~ 2L,
    TRUE             ~ 3L
  )
  tibble(albi_score = score, albi_grade = grade)
}

# C-index（Harrell）— CoxのLP（大きい=ハザード大）に対しreverse=TRUEで“正しい向き”
c_index <- function(time, event, lp){
  survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
}

# 簡易補完（数値=中央値、因子=最頻）
Mode <- function(x){ ux <- unique(x[!is.na(x)]); if(length(ux)==0) return(NA); ux[which.max(tabulate(match(x, ux)))] }
impute_simple <- function(df){
  num_cols <- names(df)[sapply(df, is.numeric)]
  fac_cols <- names(df)[sapply(df, is.factor)]
  if(length(num_cols)) df[num_cols] <- lapply(df[num_cols], function(x){ if(all(is.na(x))) x else { x[is.na(x)] <- median(x, na.rm=TRUE); x }})
  if(length(fac_cols)) df[fac_cols] <- lapply(df[fac_cols], function(x){ if(all(is.na(x))) x else { x[is.na(x)] <- Mode(x); droplevels(x) }})
  df
}

```

# CHUNK1-BRサブセット作成・特徴りょう生成
```{r}
## ==== CHUNK 1: Build ds02 (BRのみ・特徴量) ====
need_cols(ds01_model, c(var_map$id, var_map$sex, var_map$alb_g_dl, var_map$tbil_mg_dl,
                        var_map$afp_ng_ml, var_map$tum_diam_cm, var_map$tum_count,
                        var_map$time_months, var_map$event_recur,
                        var_map$t_cat, var_map$n_cat, var_map$m_cat,
                        var_map$vp_pre, var_map$vv_pre, var_map$vp_path, var_map$vv_path,
                        var_map$op_date, var_map$group_rb, var_map$stage_diag))

# group_rb の補完
ds02 <- ds01_model %>%
  mutate(
    group_rb_fill = dplyr::case_when(
      !is.na(.data[[var_map$group_rb]]) ~ .data[[var_map$group_rb]],
      .data[[var_map$stage_diag]] %in% c("BR1","BR2") ~ "BR",
      .data[[var_map$stage_diag]] %in% c("R") ~ "R",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(group_rb_fill == "BR") %>%                         # BRのみ残す
  mutate(
    op_date = as.Date(.data[[var_map$op_date]]),
    sex_male = dplyr::case_when(.data[[var_map$sex]] %in% c("M","m") ~ 1,
                                .data[[var_map$sex]] %in% c("F","f") ~ 0,
                                TRUE ~ NA_real_)
  ) %>%
  bind_cols(calc_albi( .[[var_map$alb_g_dl]], .[[var_map$tbil_mg_dl]] )) %>%
  mutate(
    albi23    = if_else(albi_grade >= 2, 1, 0, missing = NA_integer_),
    ln_afp    = safe_ln( .[[var_map$afp_ng_ml]] ),
    ln_diam   = safe_ln( .[[var_map$tum_diam_cm]] ),
    tum_count = suppressWarnings(as.numeric(.data[[var_map$tum_count]])),
    time      = suppressWarnings(as.numeric(.data[[var_map$time_months]])),
    event     = as.integer(.data[[var_map$event_recur]]),

    # TNM（factor; 参照は最小レベル）
    T_cat = factor(.data[[var_map$t_cat]]),
    N_cat = factor(.data[[var_map$n_cat]]),
    M_cat = factor(.data[[var_map$m_cat]])
  )

# relevel
ds02$T_cat <- relevel(ds02$T_cat, ref = levels(ds02$T_cat)[1])
ds02$N_cat <- relevel(ds02$N_cat, ref = levels(ds02$N_cat)[1])
ds02$M_cat <- relevel(ds02$M_cat, ref = levels(ds02$M_cat)[1])

# mvi_01: (vp_pre==0 & vp_path>=1) OR (vv_pre==0 & vv_path>=1)
ds02 <- ds02 %>%
  mutate(
    vp_pre_num  = suppressWarnings(as.numeric(.data[[var_map$vp_pre]])),
    vv_pre_num  = suppressWarnings(as.numeric(.data[[var_map$vv_pre]])),
    vp_path_num = suppressWarnings(as.numeric(.data[[var_map$vp_path]])),
    vv_path_num = suppressWarnings(as.numeric(.data[[var_map$vv_path]])),
    mvi_01 = case_when(
      (vp_pre_num == 0 & vp_path_num >= 1) | (vv_pre_num == 0 & vv_path_num >= 1) ~ 1L,
      is.na(vp_pre_num) & is.na(vv_pre_num) & is.na(vp_path_num) & is.na(vv_path_num) ~ NA_integer_,
      TRUE ~ 0L
    )
  ) %>%
  dplyr::select(-dplyr::all_of(c("vp_pre_num","vv_pre_num","vp_path_num","vv_path_num")))

```

# CHUNK2-時間分割(ds04_train/ds05_val/ds06_test)
```{r}
## ==== CHUNK 2: Temporal split (quantile-based, Date-safe) ====
stopifnot(exists("ds02"))
ds02 <- ds02 %>% filter(!is.na(op_date)) %>% arrange(op_date)

# 目標割合と最小件数
targets <- list(
  c(0.70, 0.15, 0.15),
  c(0.65, 0.175, 0.175),
  c(0.60, 0.20, 0.20),
  c(0.55, 0.225, 0.225),
  c(0.50, 0.25, 0.25)
)
min_n_each <- 30

split_ok <- FALSE
od_num <- as.numeric(ds02$op_date)  # days since 1970-01-01

for (p in targets) {
  p_train <- p[1]; p_val <- p[2]; p_test <- p[3]

  # Date を数値にして分位点 → Date に戻す
  q1_num <- stats::quantile(od_num, probs = p_train, na.rm = TRUE, type = 7)
  q2_num <- stats::quantile(od_num, probs = p_train + p_val, na.rm = TRUE, type = 7)
  q1 <- as.Date(q1_num, origin = "1970-01-01")
  q2 <- as.Date(q2_num, origin = "1970-01-01")

  # q1==q2 のときは、次のユニーク日付へずらす
  if (!is.finite(q1) || !is.finite(q2) || q1 >= q2) {
    uniq_dates <- sort(unique(ds02$op_date))
    pos <- which(uniq_dates >= q1)[1]
    if (!is.na(pos) && pos < length(uniq_dates)) {
      q2 <- uniq_dates[pos + 1]
    } else {
      q1 <- uniq_dates[max(1, length(uniq_dates) - 2)]
      q2 <- uniq_dates[max(1, length(uniq_dates) - 1)]
    }
  }

  ds04_train <- ds02 %>% filter(op_date <= q1)
  ds05_val   <- ds02 %>% filter(op_date >  q1 & op_date <= q2)
  ds06_test  <- ds02 %>% filter(op_date >  q2)

  # Cox の要件: time>0
  ds04_train <- ds04_train %>% filter(is.finite(time), time > 0)
  ds05_val   <- ds05_val   %>% filter(is.finite(time), time > 0)
  ds06_test  <- ds06_test  %>% filter(is.finite(time), time > 0)

  if (nrow(ds04_train) >= min_n_each &&
      nrow(ds05_val)   >= min_n_each &&
      nrow(ds06_test)  >= min_n_each) {
    split_ok <- TRUE
    message(sprintf("Temporal split: %.0f/%.0f/%.0f%%  q1=%s  q2=%s  (n=%d/%d/%d)",
                    100*p_train, 100*p_val, 100*p_test,
                    as.character(q1), as.character(q2),
                    nrow(ds04_train), nrow(ds05_val), nrow(ds06_test)))
    break
  }
}

if (!split_ok) {
  warning("最小件数に届きません。最後の割合で続行。min_n_each や targets を調整してください。")
}

# サマリ
summarize_split <- function(d, name) {
  cat(sprintf("%s: n=%d, events=%d, first=%s, last=%s\n",
              name, nrow(d), sum(d$event != 0, na.rm = TRUE),
              ifelse(nrow(d)>0, as.character(min(d$op_date)), NA),
              ifelse(nrow(d)>0, as.character(max(d$op_date)), NA)))
}
summarize_split(ds04_train, "ds04_train")
summarize_split(ds05_val,   "ds05_val")
summarize_split(ds06_test,  "ds06_test")

```


# CHUNK3-Baseline model: ERASL_pre / ERASL_post / TNM (Train -> Test評価)
```{r}
## ==== CHUNK 3: Baselines (complete-case + tiny ridge to avoid separation) ====

# 1) 完全ケース抽出（ERASL-pre/post 用）
vars_pre  <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","time","event")
vars_post <- c(vars_pre, "mvi_01")

ds08_pre_train <- ds04_train %>% tidyr::drop_na(all_of(vars_pre))
ds09_pre_test  <- ds06_test  %>% tidyr::drop_na(all_of(vars_pre))

ds10_post_train <- ds04_train %>% tidyr::drop_na(all_of(vars_post))
ds11_post_test  <- ds06_test  %>% tidyr::drop_na(all_of(vars_post))

# 2) ERASL-pre（微小ridgeで発散回避）
fit_erasl_pre <- coxph(
  Surv(time, event) ~ ridge(sex_male, albi23, ln_afp, ln_diam, tum_count, theta = 1e-6),
  data = ds08_pre_train, ties = "efron"
)
b_erasl_pre <- broom::tidy(fit_erasl_pre, exponentiate = TRUE, conf.int = TRUE)

lp_pre_test <- predict(fit_erasl_pre, newdata = ds09_pre_test, type = "lp")
c_pre_test  <- c_index(ds09_pre_test$time, ds09_pre_test$event, lp_pre_test)

# 3) ERASL-post（同様に ridge）
fit_erasl_post <- coxph(
  Surv(time, event) ~ ridge(sex_male, albi23, ln_afp, ln_diam, tum_count, mvi_01, theta = 1e-6),
  data = ds10_post_train, ties = "efron"
)
b_erasl_post <- broom::tidy(fit_erasl_post, exponentiate = TRUE, conf.int = TRUE)

lp_post_test <- predict(fit_erasl_post, newdata = ds11_post_test, type = "lp")
c_post_test  <- c_index(ds11_post_test$time, ds11_post_test$event, lp_post_test)

# 4) TNM（こちらは従来どおり）
fit_tnm <- coxph(Surv(time, event) ~ T_cat + N_cat + M_cat,
                 data = ds04_train %>% tidyr::drop_na(T_cat, N_cat, M_cat, time, event),
                 ties = "efron")
b_tnm <- broom::tidy(fit_tnm, exponentiate = TRUE, conf.int = TRUE)

lp_tnm_test <- predict(fit_tnm, newdata = ds06_test %>% tidyr::drop_na(T_cat, N_cat, M_cat, time, event), type = "lp")
c_tnm_test  <- c_index((ds06_test %>% tidyr::drop_na(T_cat, N_cat, M_cat, time, event))$time,
                       (ds06_test %>% tidyr::drop_na(T_cat, N_cat, M_cat, time, event))$event,
                       lp_tnm_test)

list(
  C_ERASL_pre_test  = c_pre_test,
  C_ERASL_post_test = c_post_test,
  C_TNM_test        = c_tnm_test
)

```

# CHUNK4-LASSO (ERASL-postの6変数は常に含める) + α/λチューニング (Train -> val)
```{r}
## ==== CHUNK 4: LASSO with core forced-in (Train tune on Val; column-align) ====

# 候補（t/n/mは使わず、T_cat/N_cat/M_catは使う）
core_vars  <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")  # 常に入れる
extra_vars <- c(
  "T_cat","N_cat","M_cat",
  "tum_diam_pre","tum_count_pre","vp_pre","vv_pre","n_pre","m_pre","age","sex",
  "hbv","hcv","plt","alb","tbil","che","ast","alt","nh3","pt_inr","icg10_cat","icg_r15",
  "hh15","lhl15","liver_damage","child_pugh","afp","afp_l3","pivka2","cea","ca19_9",
  "height_cm","weight_kg","ps","asa","op_time_min","bleed_ml","max_diam_cm","grouth_type",
  "vp_path","vv_path","va_path","b_path","fc","fc_inf","sf","lm","sm","sm_mm",
  "stage","fibrosis_score","grading_score"
)
candidates <- unique(c(core_vars, extra_vars))
candidates <- intersect(candidates, names(ds02))

# ---- 前処理“学習（Train基準）” & 変換関数 ----
Mode <- function(x){ ux <- unique(x[!is.na(x)]); if(length(ux)==0) return(NA); ux[which.max(tabulate(match(x, ux)))] }

fit_preproc <- function(df, vars){
  X <- df %>% dplyr::select(all_of(vars)) %>% mutate(across(where(is.character), as.factor))
  # 明示的に因子化（存在すれば）
  for(cn in c("T_cat","N_cat","M_cat")) if(cn %in% names(X)) X[[cn]] <- factor(X[[cn]])
  # 補完パラメータ（Trainで学習）
  num_cols <- names(X)[sapply(X, is.numeric)]
  fac_cols <- names(X)[sapply(X, is.factor)]
  num_median <- setNames(lapply(X[num_cols], function(x) median(x, na.rm=TRUE)), num_cols)
  fac_mode   <- setNames(lapply(X[fac_cols], Mode), fac_cols)
  fac_levels <- setNames(lapply(X[fac_cols], levels), fac_cols)
  # 補完＆行列化
  if(length(num_cols)) X[num_cols] <- Map(function(x,m){ x[is.na(x)] <- m; x }, X[num_cols], num_median)
  if(length(fac_cols)) X[fac_cols] <- Map(function(x,m){ x[is.na(x)] <- m; droplevels(x) }, X[fac_cols], fac_mode)
  mm <- model.matrix(~ 0 + ., data = X)
  # Trainで定数列は削除（Val/Testも同じ列集合に強制）
  keep <- if(ncol(mm)) which(apply(mm, 2, sd) > 0) else integer(0)
  mm_keep <- if(length(keep)) mm[, keep, drop=FALSE] else matrix(0, nrow=nrow(X), ncol=0)
  list(
    vars=vars, num_median=num_median, fac_mode=fac_mode, fac_levels=fac_levels,
    ref_cols=colnames(mm_keep), mm=mm_keep
  )
}

transform_preproc <- function(prep, df){
  X <- df %>% dplyr::select(all_of(prep$vars)) %>% mutate(across(where(is.character), as.factor))
  # 因子水準を Train に合わせる
  for(cn in names(prep$fac_levels)){
    if(cn %in% names(X)) X[[cn]] <- factor(X[[cn]], levels=prep$fac_levels[[cn]])
  }
  # Trainのパラメータで補完
  for(cn in names(prep$num_median)){
    if(cn %in% names(X)){ x <- X[[cn]]; x[is.na(x)] <- prep$num_median[[cn]]; X[[cn]] <- x }
  }
  for(cn in names(prep$fac_mode)){
    if(cn %in% names(X)){ x <- X[[cn]]; x[is.na(x)] <- prep$fac_mode[[cn]]; X[[cn]] <- droplevels(x) }
  }
  mm <- model.matrix(~ 0 + ., data = X)
  # 列を Train に合わせて整列（足りない列は0、余計な列は落とす）
  cur  <- colnames(mm)
  extra <- setdiff(cur, prep$ref_cols)
  if(length(extra)) mm <- mm[, setdiff(cur, extra), drop=FALSE]
  miss <- setdiff(prep$ref_cols, colnames(mm))
  if(length(miss)) mm <- cbind(mm, matrix(0, nrow=nrow(mm), ncol=length(miss), dimnames=list(NULL, miss)))
  mm <- mm[, prep$ref_cols, drop=FALSE]
  mm
}

# ---- Train / Val デザイン行列（Train基準で整列）----
prep <- fit_preproc(ds04_train, candidates)
x_tr <- prep$mm
y_tr <- Surv(ds04_train$time, as.integer(ds04_train$event != 0))

x_va <- transform_preproc(prep, ds05_val)
y_va <- Surv(ds05_val$time, as.integer(ds05_val$event != 0))

# ---- penalty.factor：ERASL-post 6変数は強制（=0）、他は1 ----
pf <- rep(1, ncol(x_tr))
force_exact <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")
is_forced <- colnames(x_tr) %in% force_exact  # 数値列はそのまま列名になる
pf[is_forced] <- 0

# ---- α/λ チューニング（ValのC-index最大で選択）----
alpha_grid <- c(0.25, 0.5, 0.75, 1.0)
best <- list(cidx=-Inf, alpha=NA, lambda=NA, beta=NULL)

for(a in alpha_grid){
  fit_path <- glmnet(x = x_tr, y = y_tr, family = "cox",
                     alpha = a, nlambda = 600,
                     penalty.factor = pf, standardize = TRUE)
  if(is.null(fit_path$lambda)) next
  B <- as.matrix(coef(fit_path))
  for(j in seq_along(fit_path$lambda)){
    beta <- B[, j, drop=FALSE]
    lp_va <- as.numeric(x_va %*% beta)
    c_va  <- survival::concordance(y_va ~ lp_va, reverse = TRUE)$concordance
    if(is.finite(c_va) && c_va > best$cidx){
      best <- list(cidx=c_va, alpha=a, lambda=fit_path$lambda[j], beta=beta)
    }
  }
}

best  # <- α, λ, Val C-index を確認

```

```{r}
## ==== CHUNK 4-DIAG: Train+Val vs Test の設計行列ズレ診断 ====
# 前提: ds04_train, ds05_val, ds06_test, ds02 が存在

# 1) 候補セット（CHUNK4で使っているものと同じにする）
core_vars  <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")
extra_vars <- c(
  "T_cat","N_cat","M_cat",
  "tum_diam_pre","tum_count_pre","vp_pre","vv_pre","n_pre","m_pre","age","sex",
  "hbv","hcv","plt","alb","tbil","che","ast","alt","nh3","pt_inr","icg10_cat","icg_r15",
  "hh15","lhl15","liver_damage","child_pugh","afp","afp_l3","pivka2","cea","ca19_9",
  "height_cm","weight_kg","ps","asa","op_time_min","bleed_ml","max_diam_cm","grouth_type",
  "vp_path","vv_path","va_path","b_path","fc","fc_inf","sf","lm","sm","sm_mm",
  "stage","fibrosis_score","grading_score"
)
candidates <- unique(intersect(c(core_vars, extra_vars), names(ds02)))

# 2) 前処理なしだと NA/型で落ちるので、最小限の“診断用”前処理
Mode <- function(x){ ux <- unique(x[!is.na(x)]); if(length(ux)==0) return(NA); ux[which.max(tabulate(match(x, ux)))] }
diag_build_mm <- function(df, vars){
  X <- df %>% dplyr::select(all_of(vars))
  # 文字は因子化、T/N/M は明示因子化（存在すれば）
  X <- X %>% mutate(across(where(is.character), as.factor))
  for(cn in c("T_cat","N_cat","M_cat")) if(cn %in% names(X)) X[[cn]] <- factor(X[[cn]])
  # 単純補完（数値=中央値、因子=最頻）
  num_cols <- names(X)[sapply(X, is.numeric)]
  fac_cols <- names(X)[sapply(X, is.factor)]
  if(length(num_cols)) X[num_cols] <- lapply(X[num_cols], function(z){ if(all(is.na(z))) z else { z[is.na(z)] <- median(z, na.rm=TRUE); z }})
  if(length(fac_cols)) X[fac_cols] <- lapply(X[fac_cols], function(z){ m <- Mode(z); z[is.na(z)] <- m; droplevels(z) })
  # ダミー化（切片なし）。ここでは“定数列は削除しない”で生の列を出す
  mm <- model.matrix(~ 0 + ., data = X)
  list(mm=mm, X=X)
}

# 3) データ準備
ds07_trva <- dplyr::bind_rows(ds04_train, ds05_val)

# 4) 設計行列の作成
trva <- diag_build_mm(ds07_trva, candidates)
te   <- diag_build_mm(ds06_test,  candidates)
mm_trva <- trva$mm
mm_te   <- te$mm

cat("---- Matrix dims ----\n")
cat("Train+Val rows:", nrow(mm_trva), " cols:", ncol(mm_trva), "\n")
cat("Test      rows:", nrow(mm_te),   " cols:", ncol(mm_te),   "\n")

# 5) 列名の差分
cols_trva <- colnames(mm_trva)
cols_te   <- colnames(mm_te)
only_in_trva <- setdiff(cols_trva, cols_te)
only_in_te   <- setdiff(cols_te,   cols_trva)

cat("\n---- Column set differences ----\n")
cat("Columns ONLY in Train+Val (count=", length(only_in_trva), "):\n", paste(utils::head(only_in_trva, 20), collapse=", "), if(length(only_in_trva)>20) " ...", "\n", sep="")
cat("Columns ONLY in Test      (count=", length(only_in_te),   "):\n", paste(utils::head(only_in_te, 20),   collapse=", "), if(length(only_in_te)>20) " ...", "\n", sep="")

# 6) 定数列（分散0）の有無
sd_trva <- apply(mm_trva, 2, sd)
sd_te   <- apply(mm_te,   2, sd)
const_trva <- names(sd_trva)[sd_trva == 0]
const_te   <- names(sd_te)[sd_te == 0]
cat("\n---- Zero-variance columns ----\n")
cat("Train+Val const (", length(const_trva), "): ", paste(utils::head(const_trva, 20), collapse=", "),
    if(length(const_trva)>20) " ...", "\n", sep="")
cat("Test      const (", length(const_te),   "): ", paste(utils::head(const_te, 20),   collapse=", "),
    if(length(const_te)>20) " ...", "\n", sep="")

# 7) 因子候補ごとの“水準ズレ”チェック
fac_cands <- candidates[sapply(ds02[candidates], function(z) is.factor(z) || is.character(z))]
fac_cands <- unique(c(fac_cands, intersect(c("T_cat","N_cat","M_cat"), candidates)))
cat("\n---- Factor level differences (Train+Val vs Test) ----\n")
for(v in fac_cands){
  if(!v %in% names(ds07_trva) || !v %in% names(ds06_test)) next
  lev_trva <- levels(factor(ds07_trva[[v]]))
  lev_te   <- levels(factor(ds06_test[[v]]))
  add_in_trva <- setdiff(lev_trva, lev_te)
  add_in_te   <- setdiff(lev_te,   lev_trva)
  if(length(add_in_trva) || length(add_in_te)){
    cat(sprintf("%s: levels_train+val=%s | levels_test=%s\n",
                v,
                paste(lev_trva, collapse="|"),
                paste(lev_te,   collapse="|")))
    if(length(add_in_trva)) cat("  only_in_train+val:", paste(add_in_trva, collapse=","), "\n")
    if(length(add_in_te))   cat("  only_in_test     :", paste(add_in_te,   collapse=","), "\n")
  }
}

# 8) 強制投入コア6変数の存在確認とNA率（0/1や数値列として列があるか）
core_present_trva <- core_vars %in% cols_trva
core_present_te   <- core_vars %in% cols_te
cat("\n---- Core 6 presence ----\n")
print(data.frame(var=core_vars, in_train_val=core_present_trva, in_test=core_present_te, row.names=NULL))

na_rate <- function(x) mean(is.na(x))
core_na_trva <- sapply(core_vars, function(v) if(v %in% names(ds07_trva)) na_rate(ds07_trva[[v]]) else NA)
core_na_te   <- sapply(core_vars, function(v) if(v %in% names(ds06_test))   na_rate(ds06_test[[v]]) else NA)
cat("\nNA rate (raw features)\n")
print(data.frame(var=core_vars, train_val=core_na_trva, test=core_na_te, row.names=NULL))

cat("\n[DIAG DONE]\n")

```

# CHUNK5-最終モデルの作成 (Train+Valで再学習) -> Test評価
```{r}
## ==== CHUNK 5: Refit on Train+Val and Evaluate on Test (column-aligned) ====
stopifnot(exists("best"), is.finite(best$alpha), is.finite(best$lambda))
stopifnot(exists("ds04_train"), exists("ds05_val"), exists("ds06_test"))
stopifnot(exists("fit_preproc"), exists("transform_preproc"))  # CHUNK4の関数を使います
stopifnot(exists("candidates"))

# 1) Train+Val を結合
ds07_trva <- dplyr::bind_rows(ds04_train, ds05_val)

# 2) 前処理を Train+Val で“学習”して列集合を固定
prep2  <- fit_preproc(ds07_trva, candidates)   # → prep2$ref_cols が基準列
x_trva <- prep2$mm
y_trva <- survival::Surv(ds07_trva$time, as.integer(ds07_trva$event != 0))

# 3) Test には同じ前処理を“適用”（余分な列は落とし、足りない列は0で補う）
x_te <- transform_preproc(prep2, ds06_test)
y_te <- survival::Surv(ds06_test$time, as.integer(ds06_test$event != 0))
stopifnot(identical(colnames(x_trva), colnames(x_te)))

# 4) ERASL-post の6変数は強制投入（penalty.factor=0）
pf2 <- rep(1, ncol(x_trva))
force_exact <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")
pf2[colnames(x_trva) %in% force_exact] <- 0

# 5) Valで選んだ α, λ で最終学習（Train+Val）
fit_final <- glmnet(x = x_trva, y = y_trva, family = "cox",
                    alpha = best$alpha, lambda = best$lambda,
                    penalty.factor = pf2, standardize = TRUE)

# 6) Test で性能評価（向きは reverse=TRUE で正）
lp_test <- as.numeric(x_te %*% as.matrix(coef(fit_final)))
c_test  <- survival::concordance(y_te ~ lp_test, reverse = TRUE)$concordance

list(
  best_alpha  = best$alpha,
  best_lambda = best$lambda,
  cindex_test = c_test,
  n_trainval  = nrow(ds07_trva),
  n_test      = nrow(ds06_test)
)

```
```{r}
## ==== CHUNK 6: Collect C-index (ERASL-pre/post, TNM, LASSO) ====

library(survival)
c_index <- function(time, event, lp){
  survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
}

# ない場合は再計算するためのヘルパ
cidx_from_fit <- function(fit, need_vars){
  stopifnot(exists("ds06_test"))
  test_common <- ds06_test |> tidyr::drop_na(all_of(c(need_vars, "time","event")))
  if(nrow(test_common) == 0) return(NA_real_)
  lp <- predict(fit, newdata = test_common, type = "lp")
  c_index(test_common$time, test_common$event, lp)
}

results <- list()

# ERASL-pre
if (exists("c_pre_test")) {
  results$ERASL_pre <- c_pre_test
} else if (exists("fit_erasl_pre")) {
  results$ERASL_pre <- cidx_from_fit(fit_erasl_pre,
    c("sex_male","albi23","ln_afp","ln_diam","tum_count"))
}

# ERASL-post
if (exists("c_post_test")) {
  results$ERASL_post <- c_post_test
} else if (exists("fit_erasl_post")) {
  results$ERASL_post <- cidx_from_fit(fit_erasl_post,
    c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01"))
}

# TNM
if (exists("c_tnm_test")) {
  results$TNM <- c_tnm_test
} else if (exists("fit_tnm")) {
  results$TNM <- cidx_from_fit(fit_tnm, c("T_cat","N_cat","M_cat"))
}

# LASSO（CHUNK5で作った最終モデル）
if (exists("c_test")) {
  results$LASSO <- c_test
} else if (exists("fit_final")) {
  # Train+Val基準の前処理オブジェクト（prepまたはprep2）を使って Test を行列化
  if (exists("prep2")) {
    mm_te <- transform_preproc(prep2, ds06_test)         # CHUNK5のprep2
  } else if (exists("prep")) {
    mm_te <- transform_preproc(prep,  ds06_test)         # CHUNK4のprep
  } else {
    stop("LASSOの前処理オブジェクト（prep/prep2）が見つかりません。")
  }
  lp <- as.numeric(mm_te %*% as.matrix(coef(fit_final)))
  results$LASSO <- c_index(ds06_test$time, as.integer(ds06_test$event != 0), lp)
}

# リスト or 表で出力
results
# tibbleにしたい場合は↓
# tibble::tibble(model = names(results), c_index = unlist(results))

```

# 追加パッケージ
```{r}
## ==== CHUNK A: Packages & Helpers ====
req_pkgs <- c("tidyverse","survival","timeROC","splines")
to_install <- setdiff(req_pkgs, rownames(installed.packages()))
if(length(to_install)) install.packages(to_install, Ncpus = 2)
invisible(lapply(req_pkgs, library, character.only = TRUE))

# c-index（向きは正）
c_index <- function(time, event, lp){
  survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
}

# 台形公式
trapz <- function(x, y){
  idx <- order(x); x <- x[idx]; y <- y[idx]
  sum((x[-1]-x[-length(x)]) * (y[-1]+y[-length(y)]) / 2)
}

```
```{r}
## ==== CHUNK B-FIX: 安全版 transform_preproc（単一水準の因子を自動救済） ====
transform_preproc_safe <- function(prep, df){
  X <- df %>%
    dplyr::select(dplyr::all_of(prep$vars)) %>%
    dplyr::mutate(across(where(is.character), as.factor))

  # Train 側の因子レベルに合わせる
  for (cn in names(prep$fac_levels)) {
    if (cn %in% names(X)) {
      X[[cn]] <- factor(X[[cn]], levels = prep$fac_levels[[cn]])
    }
  }

  # Train の中央値/最頻値で補完
  for (cn in names(prep$num_median)) if (cn %in% names(X)) {
    v <- X[[cn]]; v[is.na(v)] <- prep$num_median[[cn]]; X[[cn]] <- v
  }
  for (cn in names(prep$fac_mode)) if (cn %in% names(X)) {
    v <- X[[cn]]; v[is.na(v)] <- prep$fac_mode[[cn]]; X[[cn]] <- droplevels(v)
  }

  # ★ 単一水準の因子にダミーレベルを追加（例: "__dummy__"）
  fac_cols <- names(X)[sapply(X, is.factor)]
  for (cn in fac_cols) {
    if (nlevels(X[[cn]]) <= 1) {
      cur <- levels(X[[cn]])
      new_levels <- unique(c(if(length(cur)) cur else as.character(X[[cn]]), "__dummy__"))
      X[[cn]] <- factor(as.character(X[[cn]]), levels = new_levels)
    }
  }

  # ダミー化
  mm <- model.matrix(~ 0 + ., data = X)

  # 列を Train 基準に合わせる（不足は0埋め、余剰は落とす）
  cur   <- colnames(mm)
  extra <- setdiff(cur, prep$ref_cols)
  if (length(extra)) mm <- mm[, setdiff(cur, extra), drop = FALSE]
  miss  <- setdiff(prep$ref_cols, colnames(mm))
  if (length(miss)) {
    mm <- cbind(mm, matrix(0, nrow = nrow(mm), ncol = length(miss),
                           dimnames = list(NULL, miss)))
  }
  mm <- mm[, prep$ref_cols, drop = FALSE]
  mm
}

```


# 共通テスト集合の作成 & LP算出（全モデル同一データで比較）
```{r}
## ==== CHUNK B: Common test set & linear predictors ====
stopifnot(exists("ds06_test"))

# 必要列（ERASL-post ⊇ ERASL-pre, ＋ TNM）
vars_pre   <- c("sex_male","albi23","ln_afp","ln_diam","tum_count")
vars_post  <- c(vars_pre, "mvi_01")
vars_tnm   <- c("T_cat","N_cat","M_cat")
vars_common <- c(unique(c(vars_post, vars_tnm)), "time","event")

test_common <- ds06_test %>% tidyr::drop_na(all_of(vars_common))
message("Common test n = ", nrow(test_common))

# ---- LP: ERASL-pre/post/TNM ----
stopifnot(exists("fit_erasl_pre"), exists("fit_erasl_post"), exists("fit_tnm"))
lp_pre  <- predict(fit_erasl_pre,  newdata = test_common, type = "lp")
lp_post <- predict(fit_erasl_post, newdata = test_common, type = "lp")
lp_tnm  <- predict(fit_tnm,        newdata = test_common, type = "lp")

## ---- LP: LASSO（Train基準の前処理をTestへ適用）----
stopifnot(exists("fit_final"))
mm_te <- if (exists("prep2")) transform_preproc_safe(prep2, test_common) else transform_preproc_safe(prep, test_common)
beta_lasso <- as.matrix(coef(fit_final))
lp_lasso <- as.numeric(mm_te %*% beta_lasso)


# まとめ
y_time  <- test_common$time
y_event <- as.integer(test_common$event != 0)

```


# ブートストラップCI（TestでB=1000）
```{r}
## ==== PATCH for CHUNK C (Bootstrap CI) ====
set.seed(123)
B <- 1000
n <- nrow(test_common)

boot_c <- function(lp){
  out <- numeric(B)
  for(b in 1:B){
    idx <- sample.int(n, n, replace = TRUE)
    out[b] <- c_index(y_time[idx], y_event[idx], lp[idx])
  }
  out <- out[is.finite(out)]               # たまに NA になるブートサンプルを除外
  qs <- quantile(out, c(0.025, 0.975), na.rm = TRUE)  # ← 名前付きベクトル
  c(mean = mean(out, na.rm = TRUE),
    lo   = unname(qs[1]),                  # ← 名前を外す
    hi   = unname(qs[2]))
}

ci_pre   <- boot_c(lp_pre)
ci_post  <- boot_c(lp_post)
ci_tnm   <- boot_c(lp_tnm)
ci_lasso <- boot_c(lp_lasso)

tibble::tibble(
  model  = c("ERASL_pre","ERASL_post","TNM","LASSO"),
  c_mean = c(ci_pre["mean"], ci_post["mean"], ci_tnm["mean"], ci_lasso["mean"]),
  c_lo   = c(ci_pre["lo"],   ci_post["lo"],   ci_tnm["lo"],   ci_lasso["lo"]),
  c_hi   = c(ci_pre["hi"],   ci_post["hi"],   ci_lasso["hi"], ci_lasso["hi"]),  # ← ここタイプミス注意
  over_0_5 = c(ci_pre["lo"],ci_post["lo"],ci_tnm["lo"],ci_lasso["lo"]) > 0.5
)

```


# 時点依存AUC(t) と iAUC（1,3,5年）
```{r}
## ==== CHUNK D: time-dependent AUC(t) & iAUC(1-5y) ====
# timeROC は "months" 前提で 12/36/60 を指定
tau_vec <- c(12, 36, 60)
tau_grid <- 12:60  # iAUC を月単位で近似平均

auc_time <- function(lp, times){
  tr <- timeROC(T = y_time, delta = y_event, marker = lp,
                cause = 1, times = times, iid = FALSE)
  tr$AUC
}
iauc <- function(lp, grid){
  tr <- timeROC(T = y_time, delta = y_event, marker = lp,
                cause = 1, times = grid, iid = FALSE)
  # 区間[12,60] の正規化面積
  trapz(grid, tr$AUC) / (max(grid) - min(grid))
}

A_pre  <- auc_time(lp_pre,  tau_vec)
A_post <- auc_time(lp_post, tau_vec)
A_tnm  <- auc_time(lp_tnm,  tau_vec)
A_las  <- auc_time(lp_lasso,tau_vec)

i_pre  <- iauc(lp_pre,  tau_grid)
i_post <- iauc(lp_post, tau_grid)
i_tnm  <- iauc(lp_tnm,  tau_grid)
i_las  <- iauc(lp_lasso,tau_grid)

dplyr::bind_rows(
  tibble::tibble(model="ERASL_pre",  AUC_1y=A_pre[1],  AUC_3y=A_pre[2],  AUC_5y=A_pre[3],  iAUC_1to5=i_pre),
  tibble::tibble(model="ERASL_post", AUC_1y=A_post[1], AUC_3y=A_post[2], AUC_5y=A_post[3], iAUC_1to5=i_post),
  tibble::tibble(model="TNM",        AUC_1y=A_tnm[1],  AUC_3y=A_tnm[2],  AUC_5y=A_tnm[3],  iAUC_1to5=i_tnm),
  tibble::tibble(model="LASSO",      AUC_1y=A_las[1],  AUC_3y=A_las[2],  AUC_5y=A_las[3],  iAUC_1to5=i_las)
)

```

```{r}
## ==== DIAG for CHUNK D (timeROCの下支え確認) ====
tau_vec  <- c(12, 36, 60)
tau_grid <- 12:60

diag_time_support <- tibble::tibble(
  tau      = tau_vec,
  n_event_le_tau = sapply(tau_vec, function(t) sum(y_event == 1 & y_time <= t, na.rm=TRUE)),
  n_at_risk_tau  = sapply(tau_vec, function(t) sum(y_time >= t, na.rm=TRUE))
)
diag_time_support

```


# 特徴量見直し（log1p, カテゴリ化, RCS, MVI拡張）
```{r}
## ==== CHUNK E: Feature engineering (applied in place) ====
recode_block <- function(d){
  d %>%
    mutate(
      # tum_count: 連続 log1p + カテゴリ
      tum_count_log1p = log1p(tum_count),
      tum_count_cat = cut(tum_count,
                          breaks = c(-Inf,1,3,5,Inf),
                          labels = c("1","2-3","4-5","6+"),
                          right = TRUE, ordered_result = TRUE),

      # 径のRCSはモデル式で ns() を使う（ここではそのまま）
      # 例: Surv(...) ~ ns(tum_diam_cm, knots=quantile(tum_diam_cm, c(.1,.5,.9), na.rm=TRUE))

      # MVI拡張：vp/vv 病理の単独/両陽性カテゴリ
      vp_path_pos = as.integer(suppressWarnings(as.numeric(.data[["vp_path"]])) >= 1),
      vv_path_pos = as.integer(suppressWarnings(as.numeric(.data[["vv_path"]])) >= 1),
      mvi_combo = dplyr::case_when(
        is.na(vp_path_pos) & is.na(vv_path_pos) ~ NA_character_,
        vp_path_pos==1 & vv_path_pos==1 ~ "both",
        vp_path_pos==1 & (vv_path_pos==0 | is.na(vv_path_pos)) ~ "vp_only",
        vv_path_pos==1 & (vp_path_pos==0 | is.na(vp_path_pos)) ~ "vv_only",
        TRUE ~ "none"
      ),
      mvi_combo = factor(mvi_combo, levels=c("none","vp_only","vv_only","both"), ordered = TRUE)
    )
}

ds04_train <- recode_block(ds04_train)
ds05_val   <- recode_block(ds05_val)
ds06_test  <- recode_block(ds06_test)

```


# 前処理の一貫化（表記統一：T/N/M, HBV）
```{r}
## ==== CHUNK F: Harmonize factor levels (T/N/M/HBV) ====
harmonize_block <- function(d){
  d %>%
    mutate(
      # TNM レベルを固定（例：0〜4のみ採用、なければ欠損）
      T_cat = factor(as.character(T_cat), levels = c("0","1","2","3","4")),
      N_cat = factor(as.character(N_cat), levels = c("0","1","2","3")),
      M_cat = factor(as.character(M_cat), levels = c("0","1")),

      # HBV の表記統一（-, +, ±）
      hbv = dplyr::case_when(
        .data[["hbv"]] %in% c("-", "0", "negative","陰性") ~ "-",
        .data[["hbv"]] %in% c("+", "1", "positive","陽性") ~ "+",
        .data[["hbv"]] %in% c("±","+/-","+/−") ~ "±",
        TRUE ~ as.character(.data[["hbv"]])
      ),
      hbv = factor(hbv, levels = c("-","+","±"))
    )
}
ds04_train <- harmonize_block(ds04_train)
ds05_val   <- harmonize_block(ds05_val)
ds06_test  <- harmonize_block(ds06_test)

```


# 時系列ブロックCVで α・λ 最適化（ERASLコアは軽ペナルティ）
```{r}
## ==== CHUNK G: Time-block CV for alpha/lambda (Train only) ====
stopifnot(exists("candidates"))
source_vars <- intersect(candidates, names(ds04_train))

# 前処理（Train基準）学習
prep_tr <- fit_preproc(ds04_train, source_vars)
X_tr <- prep_tr$mm
y_tr <- Surv(ds04_train$time, as.integer(ds04_train$event != 0))

# 時系列ブロック（op_date を5分位で）
K <- 5
od <- as.numeric(as.Date(ds04_train$op_date))
cuts <- quantile(od, probs = seq(0,1,length.out=K+1), na.rm = TRUE)
foldid <- cut(od, breaks = cuts, include.lowest = TRUE, labels = FALSE)

# 罰則：ERASLコアは 0.3（完全0だと汎化悪化しやすいので“軽ペナルティ”）
pf_tr <- rep(1, ncol(X_tr))
core_exact <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")
pf_tr[colnames(X_tr) %in% core_exact] <- 0.3

alpha_grid <- c(0.25, 0.5, 0.75, 1.0)
set.seed(123)
grid_res <- list()

for(a in alpha_grid){
  cvfit <- glmnet::cv.glmnet(X_tr, y_tr, family = "cox",
                             alpha = a, foldid = foldid,
                             penalty.factor = pf_tr, nlambda = 400,
                             standardize = TRUE)
  # cv.glmnet の規準は偏尤度だが、ここでは λmin を採用
  grid_res[[as.character(a)]] <- list(alpha=a, lambda=cvfit$lambda.min,
                                      lambda_1se=cvfit$lambda.1se,
                                      cvfit=cvfit)
}

# 代表選択：lambda.1se を優先（簡潔で疎）
best_alpha <- NA; best_lambda <- NA
# ここでは a=0.5 をデフォルトにし、lambda.1se を使う例（必要なら AIC/BIC や外部Valで上書き）
if("0.5" %in% names(grid_res)){
  best_alpha  <- grid_res[["0.5"]]$alpha
  best_lambda <- grid_res[["0.5"]]$lambda_1se
} else {
  key <- names(grid_res)[1]
  best_alpha  <- grid_res[[key]]$alpha
  best_lambda <- grid_res[[key]]$lambda_1se
}

best <- list(alpha = best_alpha, lambda = best_lambda)  # 以降 CHUNK5 相当で再学習→Test
best

```


# RCS入りのモデル例（ERASL拡張の雛形）
```{r}
## ==== CHUNK H: Cox with RCS (tum_diam_pre) + engineered features ====
library(splines)

# 1) 必要列を欠損除外（Train/Test）
need_vars <- c("sex_male","albi23","ln_afp","tum_diam_pre","tum_count_log1p","mvi_combo","time","event")
train_rcs <- ds04_train %>% tidyr::drop_na(all_of(need_vars))
test_rcs  <- ds06_test  %>% tidyr::drop_na(all_of(need_vars))

stopifnot(nrow(train_rcs) > 0, nrow(test_rcs) > 0)

# 2) RCSのノットと境界をTrainで決定（固定）
#    ノットは分位点（10,50,90%）のユニーク値、境界は範囲。ノット数が足りなければ自動で線形や低次元にフォールバック。
vals_train <- train_rcs$tum_diam_pre
bknots <- range(vals_train, na.rm = TRUE)
iknots <- as.numeric(quantile(vals_train, probs = c(0.10, 0.50, 0.90), na.rm = TRUE))
iknots <- sort(unique(iknots))

# 3) 同じ基底で Train/Test の基底行列を作成
make_ns_mat <- function(x, iknots, bknots){
  if (length(iknots) >= 2) {
    splines::ns(x, knots = iknots, Boundary.knots = bknots)
  } else if (length(iknots) == 1) {
    # 内点が1つしか作れない場合：df=2 相当（1内点＋境界）
    splines::ns(x, knots = iknots, Boundary.knots = bknots)
  } else {
    # 内点を作れない場合：自然スプラインは線形（df=1相当）
    splines::ns(x, Boundary.knots = bknots, df = 1)
  }
}

B_tr <- make_ns_mat(train_rcs$tum_diam_pre, iknots, bknots)
B_te <- make_ns_mat(test_rcs$tum_diam_pre,  iknots, bknots)

# 列名を付けて結合
colnames(B_tr) <- paste0("rcs_diam", seq_len(ncol(B_tr)))
colnames(B_te) <- colnames(B_tr)  # 同じ名前に固定
train_rcs <- dplyr::bind_cols(train_rcs, as.data.frame(B_tr))
test_rcs  <- dplyr::bind_cols(test_rcs,  as.data.frame(B_te))

# 4) mvi_combo が単一水準になると推定が不安定なので、必要なら除外
use_mvi <- (is.factor(train_rcs$mvi_combo) && nlevels(train_rcs$mvi_combo) >= 2)

# 5) フォーミュラを動的生成（RCS基底は列として展開）
rhs_terms <- c("sex_male", "albi23", "ln_afp",
               colnames(B_tr),
               "tum_count_log1p",
               if (use_mvi) "mvi_combo" else NULL)
form_rcs <- as.formula(paste("Surv(time, event) ~", paste(rhs_terms, collapse = " + ")))

# 6) 学習 & テスト評価（C-indexは正向き）
fit_rcs <- coxph(form_rcs, data = train_rcs, ties = "efron")
lp_rcs  <- predict(fit_rcs, newdata = test_rcs, type = "lp")

c_index <- function(time, event, lp){
  survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
}
c_rcs <- c_index(test_rcs$time, as.integer(test_rcs$event != 0), lp_rcs)

list(
  rcs_knots          = iknots,
  rcs_boundary       = bknots,
  rcs_n_basis        = ncol(B_tr),
  mvi_combo_in_model = use_mvi,
  C_test_RCS_model   = c_rcs
)

```


# 既報式そのまま評価（ERASL published coefficients；テンプレ）
```{r}
## ==== CHUNK I: Published ERASL score (template) ====
# 下の named numeric を論文の係数で置き換えてください
# 例：erasl_coefs_pre <- c(`(Intercept)`=0.0, sex_male=..., albi23=..., ln_afp=..., ln_diam=..., tum_count=...)
#     erasl_coefs_post <- c(`(Intercept)`=0.0, sex_male=..., albi23=..., ln_afp=..., ln_diam=..., tum_count=..., mvi_01=...)

score_linear <- function(df, coefs, vars){
  X <- model.matrix(~ 1 + . , data = df[, vars, drop=FALSE])
  # 列名を係数名に合わせる（不足列は0、余剰列は落とす）
  miss <- setdiff(names(coefs), colnames(X)); if(length(miss)) X <- cbind(X, matrix(0, nrow=nrow(X), ncol=length(miss), dimnames=list(NULL, miss)))
  extra <- setdiff(colnames(X), names(coefs)); if(length(extra)) X <- X[, setdiff(colnames(X), extra), drop=FALSE]
  X <- X[, names(coefs), drop=FALSE]
  as.numeric(X %*% coefs)
}

eval_published <- function(test_df, coefs, vars){
  dat <- test_df %>% tidyr::drop_na(all_of(c(vars,"time","event")))
  if(nrow(dat) == 0) return(NA_real_)
  lp <- score_linear(dat, coefs, vars)
  c_index(dat$time, as.integer(dat$event!=0), lp)
}

# 使い方（係数を入れた後に実行）
# c_pub_pre  <- eval_published(test_common, erasl_coefs_pre,  c("sex_male","albi23","ln_afp","ln_diam","tum_count"))
# c_pub_post <- eval_published(test_common, erasl_coefs_post, c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01"))

```


```{r}
## ==== CHUNK J (FIX): helpers & preprocessing (robust) ====
req_pkgs <- c("tidyverse","survival","glmnet")
to_install <- setdiff(req_pkgs, rownames(installed.packages()))
if(length(to_install)) install.packages(to_install, Ncpus=2)
invisible(lapply(req_pkgs, library, character.only=TRUE))
# stepAIC は明示的に MASS:: を使う（library(MASS) は読み込まない）
if(!"MASS" %in% rownames(installed.packages())) install.packages("MASS")

c_index <- function(time, event, lp){
  survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
}

cc_time_only <- function(df){
  df %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))
}

# ---- LASSO用 前処理（学習側でも単一水準factorを救済）----
fit_preproc2 <- function(df, vars){
  X0 <- df %>% dplyr::select(dplyr::all_of(vars)) %>%
    dplyr::mutate(across(where(is.character), as.factor))
  fac_levels <- lapply(X0[, sapply(X0, is.factor), drop=FALSE], levels)
  num_median <- sapply(X0[, sapply(X0, is.numeric), drop=FALSE], function(x) median(x, na.rm=TRUE))
  fac_mode   <- sapply(X0[, sapply(X0, is.factor),  drop=FALSE], function(x){
    ux <- stats::na.omit(x); if(length(ux)) names(sort(table(ux), decreasing=TRUE))[1] else NA
  })
  # 欠損補完
  for (cn in names(num_median)) { v <- X0[[cn]]; v[is.na(v)] <- num_median[cn]; X0[[cn]] <- v }
  for (cn in names(fac_mode))   { v <- X0[[cn]]; v[is.na(v)] <- fac_mode[cn]; X0[[cn]] <- droplevels(v) }
  # ★ 学習側でも単一水準factorを救済
  fac_cols <- names(X0)[sapply(X0, is.factor)]
  for (cn in fac_cols) if (nlevels(X0[[cn]]) <= 1) {
    X0[[cn]] <- factor(as.character(X0[[cn]]), levels = unique(c(levels(X0[[cn]]), "__dummy__")))
  }
  mm0 <- model.matrix(~ 0 + ., data = X0)
  keep <- if(ncol(mm0)) which(apply(mm0, 2, sd) > 0) else integer(0)
  ref_cols <- if(length(keep)) colnames(mm0)[keep] else character(0)
  list(vars=vars, fac_levels=fac_levels, num_median=num_median,
       fac_mode=fac_mode, ref_cols=ref_cols)
}

transform_preproc2 <- function(prep, df){
  X <- df %>% dplyr::select(dplyr::all_of(prep$vars)) %>%
    dplyr::mutate(across(where(is.character), as.factor))
  for (cn in names(prep$fac_levels)) if (cn %in% names(X)) {
    X[[cn]] <- factor(X[[cn]], levels = prep$fac_levels[[cn]])
  }
  for (cn in names(prep$num_median)) if (cn %in% names(X)) {
    v <- X[[cn]]; v[is.na(v)] <- prep$num_median[[cn]]; X[[cn]] <- v
  }
  for (cn in names(prep$fac_mode)) if (cn %in% names(X)) {
    v <- X[[cn]]; v[is.na(v)] <- prep$fac_mode[[cn]]; X[[cn]] <- droplevels(v)
  }
  fac_cols <- names(X)[sapply(X, is.factor)]
  for (cn in fac_cols) if (nlevels(X[[cn]]) <= 1) {
    X[[cn]] <- factor(as.character(X[[cn]]), levels = unique(c(levels(X[[cn]]), "__dummy__")))
  }
  mm <- model.matrix(~ 0 + ., data = X)
  cur <- colnames(mm)
  extra <- setdiff(cur, prep$ref_cols)
  if(length(extra)) mm <- mm[, setdiff(cur, extra), drop=FALSE]
  miss <- setdiff(prep$ref_cols, colnames(mm))
  if(length(miss)) mm <- cbind(mm, matrix(0, nrow=nrow(mm), ncol=length(miss),
                                          dimnames=list(NULL, miss)))
  mm <- mm[, prep$ref_cols, drop=FALSE]
  mm
}

# 候補プール（存在列だけに絞る）
pool0 <- c(
  "sex_male","age","hbv","hcv","plt","alb","tbil","che","ast","alt","nh3",
  "pt_inr","icg10_cat","icg_r15","hh15","lhl15","liver_damage","child_pugh",
  "afp","afp_l3","pivka2","cea","ca19_9","height_cm","weight_kg","ps","asa",
  "tum_diam_pre","tum_count_pre","vp_pre","vv_pre","n_pre","m_pre",
  "max_diam_cm","grouth_type","vp_path","vv_path","va_path","b_path",
  "fc","fc_inf","sf","lm","sm","sm_mm","fibrosis_score","grading_score",
  "albi23","ln_afp","ln_diam","tum_count","mvi_01","tum_count_log1p","mvi_combo",
  "T_cat","N_cat","M_cat","op_time_min","bleed_ml","stage"
)
pool0 <- intersect(pool0, names(ds04_train))

```


```{r}
## ==== CHUNK K-DEBUG: なぜ var_superset が空かを可視化 ====
# 前提: CHUNK J 実行済み（pool0, c_index など定義済）
train0 <- ds04_train %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))
val0   <- ds05_val   %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))
test0  <- ds06_test  %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))

miss_rate <- sapply(pool0, function(v) mean(is.na(train0[[v]])))
is_single <- sapply(pool0, function(v){
  x <- train0[[v]]; if (is.null(x)) TRUE else length(unique(na.omit(x))) < 2
})

uni_screen <- function(v){
  dat <- train0 %>% dplyr::select(time, event, !!rlang::sym(v)) %>% tidyr::drop_na()
  if (nrow(dat) < 30 || sum(dat$event != 0) < 10) return(tibble::tibble(var=v, p=NA_real_, n=nrow(dat)))
  fit <- try(survival::coxph(Surv(time, event) ~ ., data=dat, ties="efron"), silent=TRUE)
  if (inherits(fit, "try-error")) return(tibble::tibble(var=v, p=NA_real_, n=nrow(dat)))
  p <- tryCatch(anova(fit)[".", "P(>|Chi|)"], error=function(e) NA_real_)
  tibble::tibble(var=v, p=as.numeric(p), n=nrow(dat))
}

uni_tab <- purrr::map_dfr(setdiff(pool0, names(which(is_single))), uni_screen) %>%
  dplyr::mutate(miss = miss_rate[var]) %>%
  dplyr::arrange(is.na(p), p, miss)

evt_train <- sum(train0$event != 0)
Kmax <- max(3, min(10, floor(evt_train/10)))
cand_ranked <- uni_tab %>% dplyr::filter(is.na(p) | is.finite(p)) %>% dplyr::pull(var)
var_superset <- unique(head(cand_ranked, Kmax))

cat("---- K-DEBUG ----\n")
cat(sprintf("Train rows=%d, events=%d, pool0=%d\n", nrow(train0), evt_train, length(pool0)))
cat(sprintf("is_single (TRUE) = %d\n", sum(is_single)))
cat("Top 10 by univariate p (var / p / miss / n):\n")
print(head(uni_tab, 10))
cat(sprintf("Kmax=%d  -> initial var_superset len=%d\n", Kmax, length(var_superset)))

```

```{r}
## ==== CHUNK K-REPLACE: 固定完全ケース & フォールバック付き stepAIC ====
fallback_superset <- function(){
  # 欠損が少なくて単一水準でないものから上位を拾う
  thr <- c(0.2, 0.4, 0.6, 1.0)
  for (t in thr){
    cand <- names(which((miss_rate <= t) & (!is_single)))
    cand <- intersect(cand, names(train0))
    if (length(cand) >= 3) return(head(cand, 8)) # 上限は8に制限
  }
  # 最後の最後の保険：とにかく存在する数値カラムから少数
  num_ok <- names(train0)[sapply(train0, is.numeric)]
  setdiff(num_ok, c("time","event"))[1:3]
}

if (length(var_superset) == 0) {
  message("var_superset が空のため、欠損率ベースのフォールバックを適用します。")
  var_superset <- fallback_superset()
}

# 固定完全ケース（同じ列で NA drop）
train_sw <- train0 %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
val_sw   <- val0   %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
test_sw  <- test0  %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()

# 行・イベントが少なすぎる場合は superset を縮める
while ((nrow(train_sw) < 30 || sum(train_sw$event!=0) < 10) && length(var_superset) > 3){
  var_superset <- head(var_superset, -1)
  train_sw <- train0 %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
  val_sw   <- val0   %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
  test_sw  <- test0  %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
}

if (length(var_superset) == 0 || nrow(train_sw) < 30 || sum(train_sw$event!=0) < 10) {
  stop(sprintf("stepAIC: 依然として母集団が小さすぎます (rows=%d, events=%d, vars=%d)。",
               nrow(train_sw), sum(train_sw$event!=0), length(var_superset)))
}

fit_start <- survival::coxph(Surv(time, event) ~ 1, data=train_sw, ties="efron", na.action=na.omit)
scope_up  <- as.formula(paste("~", paste(var_superset, collapse=" + ")))  # ここでもう空ではない

# AIC
fit_sw_aic <- MASS::stepAIC(fit_start, scope=list(lower=~1, upper=scope_up),
                            direction="both", k=2, trace=FALSE)
terms_aic  <- attr(terms(fit_sw_aic), "term.labels")

# BIC
k_bic <- log(nrow(train_sw))
fit_sw_bic <- MASS::stepAIC(fit_start, scope=list(lower=~1, upper=scope_up),
                            direction="both", k=k_bic, trace=FALSE)
terms_bic  <- attr(terms(fit_sw_bic), "term.labels")

c_idx <- function(fit, dat){
  if(!nrow(dat)) return(NA_real_)
  lp <- predict(fit, newdata=dat, type="lp")
  survival::concordance(Surv(dat$time, as.integer(dat$event!=0)) ~ lp, reverse=TRUE)$concordance
}

list(
  var_superset = var_superset,
  stepAIC_AIC_terms = terms_aic,
  C_stepAIC_AIC = list(
    C_train = c_idx(fit_sw_aic, train_sw),
    C_val   = c_idx(fit_sw_aic, val_sw),
    C_test  = c_idx(fit_sw_aic, test_sw)
  ),
  stepAIC_BIC_terms = terms_bic,
  C_stepAIC_BIC = list(
    C_train = c_idx(fit_sw_bic, train_sw),
    C_val   = c_idx(fit_sw_bic, val_sw),
    C_test  = c_idx(fit_sw_bic, test_sw)
  )
)

```


```{r}
## ==== CHUNK L (USES var_superset from K-REPLACE) ====
stopifnot(exists("var_superset"))
train_sw <- train0 %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
val_sw   <- val0   %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()
test_sw  <- test0  %>% dplyr::select(time, event, dplyr::all_of(var_superset)) %>% tidyr::drop_na()

cur <- character(0); best_valC <- -Inf
improve_min <- 0.01; max_terms <- min(10, length(var_superset))

valC_of <- function(vars){
  if(!length(vars)) return(NA_real_)
  fm  <- as.formula(paste("Surv(time, event) ~", paste(vars, collapse=" + ")))
  fit <- try(suppressWarnings(survival::coxph(fm, data=train_sw, ties="efron", na.action=na.omit)), silent=TRUE)
  if(inherits(fit,"try-error") || !is.finite(utils::tail(fit$loglik,1))) return(NA_real_)
  lp  <- try(predict(fit, newdata=val_sw, type="lp"), silent=TRUE)
  if(inherits(lp,"try-error") || all(is.na(lp))) return(NA_real_)
  survival::concordance(Surv(val_sw$time, as.integer(val_sw$event!=0)) ~ lp, reverse=TRUE)$concordance
}

repeat{
  cand <- setdiff(var_superset, cur)
  if(!length(cand) || length(cur) >= max_terms) break
  tbl <- purrr::map_dfr(cand, ~tibble::tibble(var=.x, valC=valC_of(c(cur, .x))))
  tbl <- tbl %>% dplyr::arrange(dplyr::desc(valC))
  if(!nrow(tbl) || is.na(tbl$valC[1])) break
  if(tbl$valC[1] > best_valC + improve_min){
    cur <- c(cur, as.character(tbl$var[1])); best_valC <- tbl$valC[1]
  } else break
}

fit_fwd <- if(length(cur)) survival::coxph(
  as.formula(paste("Surv(time, event) ~", paste(cur, collapse=" + "))),
  data=train_sw, ties="efron", na.action=na.omit
) else NULL

c_idx <- function(fit, dat){
  if(is.null(fit) || !nrow(dat)) return(NA_real_)
  lp <- predict(fit, newdata=dat, type="lp")
  survival::concordance(Surv(dat$time, as.integer(dat$event!=0)) ~ lp, reverse=TRUE)$concordance
}

list(
  forward_selected = cur,
  C_forward = list(
    C_train = c_idx(fit_fwd, train_sw),
    C_val   = c_idx(fit_fwd, val_sw),
    C_test  = c_idx(fit_fwd, test_sw)
  )
)

```

```{r}
## ==== CHUNK M (FIX): Stability selection (no forced vars) ====
cand_ss <- pool_clean
tr_ss <- ds04_train %>% cc_time_only()
va_ss <- ds05_val   %>% cc_time_only()
te_ss <- ds06_test  %>% cc_time_only()

prep_ss <- fit_preproc2(tr_ss, cand_ss)
X_tr <- transform_preproc2(prep_ss, tr_ss)
y_tr <- Surv(tr_ss$time, as.integer(tr_ss$event!=0))

set.seed(123)
B <- 100L; prop <- 0.8
freq <- setNames(numeric(ncol(X_tr)), colnames(X_tr))

for(b in 1:B){
  idx <- sample(seq_len(nrow(X_tr)), floor(prop*nrow(X_tr)), replace=TRUE)
  cv  <- glmnet::cv.glmnet(X_tr[idx, , drop=FALSE], y_tr[idx],
                           family="cox", alpha=0.7, nfolds=5, standardize=TRUE)
  fit <- glmnet::glmnet(X_tr[idx, , drop=FALSE], y_tr[idx],
                        family="cox", lambda=cv$lambda.1se, alpha=0.7, standardize=TRUE)
  nz  <- which(as.numeric(coef(fit)) != 0)
  if(length(nz)) freq[nz] <- freq[nz] + 1
}

sel_terms <- names(freq)[freq/B >= 0.6]
to_parent <- function(nm) sub("(.*?)[^:]*$", "\\1", gsub("[:].*$","", nm))
parents <- unique(to_parent(sel_terms))

fit_ss <- if(length(parents)) coxph(as.formula(paste("Surv(time, event) ~", paste(parents, collapse=" + "))),
                                    data = tr_ss, ties="efron", na.action=na.omit) else NULL
res_ss <- if(!is.null(fit_ss)){
  list(
    C_train = {lp <- predict(fit_ss, newdata=tr_ss, type="lp"); c_index(tr_ss$time, as.integer(tr_ss$event!=0), lp)},
    C_val   = {lp <- predict(fit_ss, newdata=va_ss, type="lp"); c_index(va_ss$time, as.integer(va_ss$event!=0), lp)},
    C_test  = {lp <- predict(fit_ss, newdata=te_ss, type="lp"); c_index(te_ss$time, as.integer(te_ss$event!=0), lp)}
  )
} else NULL

list(stability_freq = sort(freq/B, decreasing=TRUE),
     selected_parents = parents, C_stability = res_ss)

```

```{r}
## ==== CHUNK P (FIX): Plain LASSO (no forced vars) ====
cand_lasso <- pool_clean
tr_la <- ds04_train %>% cc_time_only()
va_la <- ds05_val   %>% cc_time_only()
te_la <- ds06_test  %>% cc_time_only()

prep_la_tr <- fit_preproc2(tr_la, cand_lasso)   # ★ 学習側救済が効く
X_tr <- transform_preproc2(prep_la_tr, tr_la)
y_tr <- Surv(tr_la$time, as.integer(tr_la$event!=0))

alpha_grid <- c(0.25, 0.5, 0.75, 1.0)
set.seed(123)
grid <- lapply(alpha_grid, function(a){
  cv <- glmnet::cv.glmnet(X_tr, y_tr, family="cox", alpha=a, nfolds=10, standardize=TRUE)
  list(alpha=a, cv=cv, lambda_min=cv$lambda.min, lambda_1se=cv$lambda.1se, cvm_min=min(cv$cvm, na.rm=TRUE))
})
best <- grid[[ which.min(sapply(grid, `[[`, "cvm_min")) ]]

# Train+Val で refit（前処理も Train+Val で作り直し）
trva_la <- dplyr::bind_rows(tr_la, va_la)
prep_la  <- fit_preproc2(trva_la, cand_lasso)
X_trva   <- transform_preproc2(prep_la, trva_la)
y_trva   <- Surv(trva_la$time, as.integer(trva_la$event!=0))

fit_glm <- glmnet::glmnet(X_trva, y_trva, family="cox",
                          alpha=best$alpha, lambda=best$lambda_1se, standardize=TRUE)

X_te  <- transform_preproc2(prep_la, te_la)
lp    <- as.numeric(X_te %*% as.matrix(coef(fit_glm)))
c_test <- c_index(te_la$time, as.integer(te_la$event!=0), lp)

list(best_alpha = best$alpha, best_lambda = best$lambda_1se, C_test_LASSO = c_test,
     n_selected = sum(abs(as.matrix(coef(fit_glm))) > 0))

```

```{r}
## （任意）最終比較の一覧表（Test set, Harrell's C）
grabC <- function(fit, vars){
  if(!exists(deparse(substitute(fit)))) return(NA_real_)
  if(is.null(fit)) return(NA_real_)
  dat <- cc_dat(ds06_test, vars)
  if(!nrow(dat)) return(NA_real_)
  lp  <- predict(fit, newdata = dat, type = "lp")
  c_index(dat$time, as.integer(dat$event!=0), lp)
}

res_compare <- list(
  ERASL_pre  = if(exists("fit_erasl_pre"))  grabC(fit_erasl_pre,  c("sex_male","albi23","ln_afp","ln_diam","tum_count")) else NA_real_,
  ERASL_post = if(exists("fit_erasl_post")) grabC(fit_erasl_post, c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")) else NA_real_,
  TNM        = if(exists("fit_tnm"))        grabC(fit_tnm,        c("T_cat","N_cat","M_cat")) else NA_real_,
  STEP_BIC   = grabC(fit_final_score, vars_final)
)
res_compare

```

```{r}
## ==== CHUNK Z: Compare all built models on the same Test set ====
# 前提: ds06_test があり、fit_* など各モデルが「存在する場合」はそのまま使います
# 必要パッケージ
req_pkgs <- c("tidyverse","survival","timeROC")
to_install <- setdiff(req_pkgs, rownames(installed.packages()))
if(length(to_install)) install.packages(to_install, Ncpus=2)
invisible(lapply(req_pkgs, library, character.only=TRUE))

# 既存ヘルパ（未定義なら定義）
if(!exists("c_index")){
  c_index <- function(time, event, lp){
    survival::concordance(Surv(time, event) ~ lp, reverse = TRUE)$concordance
  }
}
if(!exists("cc_dat")){
  cc_dat <- function(df, vars){
    vars <- unique(c(vars,"time","event"))
    df   <- df[, intersect(vars, names(df)), drop=FALSE]
    tidyr::drop_na(df)
  }
}
# transform_preproc_safe がない場合の後方互換
if(!exists("transform_preproc_safe") && exists("transform_preproc")){
  transform_preproc_safe <- transform_preproc
}

# 共通 Test（最低限の整備）
stopifnot(exists("ds06_test"))
test0 <- ds06_test %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))

# ---------- 共通ユーティリティ ----------
boot_ci_c <- function(time, event, lp, B=1000, seed=123){
  set.seed(seed)
  n <- length(time)
  if(n==0 || length(lp)!=n) return(c(mean=NA, lo=NA, hi=NA))
  out <- numeric(B)
  for(b in 1:B){
    idx <- sample.int(n, n, replace=TRUE)
    out[b] <- c_index(time[idx], event[idx], lp[idx])
  }
  out <- out[is.finite(out)]
  if(!length(out)) return(c(mean=NA, lo=NA, hi=NA))
  qs <- quantile(out, c(.025,.975), na.rm=TRUE)
  c(mean=mean(out, na.rm=TRUE), lo=unname(qs[1]), hi=unname(qs[2]))
}

auc_and_iauc <- function(time, event, lp, tau_vec=c(12,36,60), tau_grid=12:60){
  if(length(time)==0 || length(lp)!=length(time)) return(c(AUC_1y=NA, AUC_3y=NA, AUC_5y=NA, iAUC_1to5=NA))
  safe_timeROC <- function(times){
    tryCatch({
      tr <- timeROC(T=time, delta=event, marker=lp, cause=1, times=times, iid=FALSE)
      tr$AUC
    }, error=function(e) rep(NA_real_, length(times)))
  }
  A <- safe_timeROC(tau_vec)
  tr_grid <- tryCatch(timeROC(T=time, delta=event, marker=lp, cause=1, times=tau_grid, iid=FALSE),
                      error=function(e) NULL)
  iA <- if(!is.null(tr_grid)){
    # 台形公式
    sum((tau_grid[-1]-tau_grid[-length(tau_grid)]) * (tr_grid$AUC[-1]+tr_grid$AUC[-length(tr_grid$AUC)]) / 2) /
      (max(tau_grid)-min(tau_grid))
  } else NA_real_
  c(AUC_1y=A[1], AUC_3y=A[2], AUC_5y=A[3], iAUC_1to5=iA)
}

k_ncoef <- function(fit){
  if(inherits(fit, "coxph")){
    b <- stats::coef(fit)
    sum(is.finite(b) & b!=0)
  } else if(inherits(fit, "glmnet")){
    b <- as.matrix(coef(fit))
    sum(abs(b)>0)
  } else NA_integer_
}

# ---------- LPを作るラッパ ----------
lp_from_cox <- function(fit, need_vars, test_df=test0){
  if(!exists(deparse(substitute(fit)))) return(NULL)
  if(is.null(fit)) return(NULL)
  dat <- cc_dat(test_df, need_vars)
  if(!nrow(dat)) return(NULL)
  lp  <- predict(fit, newdata=dat, type="lp")
  list(lp=as.numeric(lp), time=dat$time, event=as.integer(dat$event!=0), n=nrow(dat))
}

lp_from_glmnet <- function(fit, prep_obj, test_df=test0){
  if(is.null(fit) || is.null(prep_obj)) return(NULL)
  # time/event の完全ケース行だけを使う（列整列は transform_preproc_safe に任せる）
  dat <- test_df %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))
  if(!nrow(dat)) return(NULL)
  mm  <- transform_preproc_safe(prep_obj, dat)
  beta <- as.matrix(coef(fit))
  lp <- as.numeric(mm %*% beta)
  list(lp=lp, time=dat$time, event=as.integer(dat$event!=0), n=nrow(dat))
}

# ---------- 個別モデルごとの取得 ----------
rows <- list()

# ERASL_pre
if(exists("fit_erasl_pre")){
  out <- lp_from_cox(fit_erasl_pre, c("sex_male","albi23","ln_afp","ln_diam","tum_count"))
  if(!is.null(out)){
    rows[["ERASL_pre"]] <- list(kind="coxph", fit=fit_erasl_pre, n=out$n, time=out$time, event=out$event, lp=out$lp)
  }
}

# ERASL_post
if(exists("fit_erasl_post")){
  out <- lp_from_cox(fit_erasl_post, c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01"))
  if(!is.null(out)){
    rows[["ERASL_post"]] <- list(kind="coxph", fit=fit_erasl_post, n=out$n, time=out$time, event=out$event, lp=out$lp)
  }
}

# TNM
if(exists("fit_tnm")){
  out <- lp_from_cox(fit_tnm, c("T_cat","N_cat","M_cat"))
  if(!is.null(out)){
    rows[["TNM"]] <- list(kind="coxph", fit=fit_tnm, n=out$n, time=out$time, event=out$event, lp=out$lp)
  }
}

# LASSO（強制入り）— CHUNK5 の fit_final / prep2 or prep
if(exists("fit_final") && (exists("prep2") || exists("prep"))){
  prep_obj <- if(exists("prep2")) prep2 else prep
  out <- lp_from_glmnet(fit_final, prep_obj, ds06_test)  # LASSO は元の ds06_test 全列から
  if(!is.null(out)){
    rows[["LASSO_forced"]] <- list(kind="glmnet", fit=fit_final, n=out$n, time=out$time, event=out$event, lp=out$lp)
  }
}

# LASSO（強制なし）— CHUNK P の fit_glm / prep_la
if(exists("fit_glm") && exists("prep_la")){
  out <- lp_from_glmnet(fit_glm, prep_la, ds06_test)
  if(!is.null(out)){
    rows[["LASSO_plain"]] <- list(kind="glmnet", fit=fit_glm, n=out$n, time=out$time, event=out$event, lp=out$lp)
  }
}

# Stepwise AIC / BIC / Forward
if(exists("fit_sw_aic")){
  tv <- attr(terms(fit_sw_aic), "term.labels")
  out <- lp_from_cox(fit_sw_aic, tv)
  if(!is.null(out)) rows[["STEP_AIC"]] <- list(kind="coxph", fit=fit_sw_aic, n=out$n, time=out$time, event=out$event, lp=out$lp)
}
if(exists("fit_sw_bic")){
  tv <- attr(terms(fit_sw_bic), "term.labels")
  out <- lp_from_cox(fit_sw_bic, tv)
  if(!is.null(out)) rows[["STEP_BIC"]] <- list(kind="coxph", fit=fit_sw_bic, n=out$n, time=out$time, event=out$event, lp=out$lp)
}
if(exists("fit_fwd") && !is.null(fit_fwd)){
  tv <- attr(terms(fit_fwd), "term.labels")
  out <- lp_from_cox(fit_fwd, tv)
  if(!is.null(out)) rows[["FORWARD"]] <- list(kind="coxph", fit=fit_fwd, n=out$n, time=out$time, event=out$event, lp=out$lp)
}

# RCS モデル（CHUNK H）
if(exists("fit_rcs") && exists("test_rcs")){
  dat <- test_rcs %>% dplyr::filter(is.finite(time), time > 0, !is.na(event))
  if(nrow(dat)){
    lp <- predict(fit_rcs, newdata=dat, type="lp")
    rows[["RCS"]] <- list(kind="coxph", fit=fit_rcs, n=nrow(dat), time=dat$time, event=as.integer(dat$event!=0), lp=as.numeric(lp))
  }
}

# Stability selection（CHUNK M）
if(exists("fit_ss") && !is.null(fit_ss)){
  tv <- attr(terms(fit_ss), "term.labels")
  out <- lp_from_cox(fit_ss, tv)
  if(!is.null(out)) rows[["StabilitySel"]] <- list(kind="coxph", fit=fit_ss, n=out$n, time=out$time, event=out$event, lp=out$lp)
}

# （必要なら）ERASL Published（係数ベクトルが存在するときのみ）
if(exists("erasl_coefs_pre")){
  need <- c("sex_male","albi23","ln_afp","ln_diam","tum_count")
  dat <- test0 %>% tidyr::drop_na(all_of(c(need,"time","event")))
  if(nrow(dat)){
    X <- model.matrix(~ 1 + ., data=dat[,need,drop=FALSE])
    miss <- setdiff(names(erasl_coefs_pre), colnames(X)); if(length(miss)) X <- cbind(X, matrix(0, nrow=nrow(X), ncol=length(miss), dimnames=list(NULL, miss)))
    extra <- setdiff(colnames(X), names(erasl_coefs_pre)); if(length(extra)) X <- X[, setdiff(colnames(X), extra), drop=FALSE]
    X <- X[, names(erasl_coefs_pre), drop=FALSE]
    lp <- as.numeric(X %*% erasl_coefs_pre)
    rows[["ERASL_published_pre"]] <- list(kind="published", fit=NULL, n=nrow(dat), time=dat$time, event=as.integer(dat$event!=0), lp=lp)
  }
}
if(exists("erasl_coefs_post")){
  need <- c("sex_male","albi23","ln_afp","ln_diam","tum_count","mvi_01")
  dat <- test0 %>% tidyr::drop_na(all_of(c(need,"time","event")))
  if(nrow(dat)){
    X <- model.matrix(~ 1 + ., data=dat[,need,drop=FALSE])
    miss <- setdiff(names(erasl_coefs_post), colnames(X)); if(length(miss)) X <- cbind(X, matrix(0, nrow=nrow(X), ncol=length(miss), dimnames=list(NULL, miss)))
    extra <- setdiff(colnames(X), names(erasl_coefs_post)); if(length(extra)) X <- X[, setdiff(colnames(X), extra), drop=FALSE]
    X <- X[, names(erasl_coefs_post), drop=FALSE]
    lp <- as.numeric(X %*% erasl_coefs_post)
    rows[["ERASL_published_post"]] <- list(kind="published", fit=NULL, n=nrow(dat), time=dat$time, event=as.integer(dat$event!=0), lp=lp)
  }
}

# ---------- 集計 ----------
if(!length(rows)) stop("比較できるモデルオブジェクトが見つかりません。先に各 CHUNK を実行してください。")

B_boot <- 1000  # ブート回数（重ければ 200 などに下げてOK）
tau_vec  <- c(12,36,60)
tau_grid <- 12:60

collect <- purrr::imap_dfr(rows, function(r, name){
  # C & CI
  ci <- boot_ci_c(r$time, r$event, r$lp, B=B_boot)
  # AUC(t), iAUC
  au <- auc_and_iauc(r$time, r$event, r$lp, tau_vec, tau_grid)
  # 係数本数
  k  <- if(!is.null(r$fit)) k_ncoef(r$fit) else NA_integer_
  tibble::tibble(
    model = name,
    n_test = r$n,
    events_test = sum(r$event==1, na.rm=TRUE),
    C = c_index(r$time, r$event, r$lp),
    C_lo = ci["lo"], C_hi = ci["hi"],
    AUC_1y = au["AUC_1y"], AUC_3y = au["AUC_3y"], AUC_5y = au["AUC_5y"],
    iAUC_1to5 = au["iAUC_1to5"],
    n_coef = k,
    over_0_5 = as.logical(ci["lo"] > 0.5)
  )
})

# C降順で表示
collect %>% dplyr::arrange(dplyr::desc(C))

```

```{r}
# ==== CHUNK0: packages ====
pkgs <- c("dplyr","survival","Hmisc","timeROC","stringr","tibble","purrr")
to_install <- pkgs[!pkgs %in% installed.packages()[,1]]
if(length(to_install)) install.packages(to_install, Ncpus = max(1, parallel::detectCores()-1))
invisible(lapply(pkgs, library, character.only = TRUE))

# ==== CHUNK1: 可変な列名マップ（あなたのデータに合わせて調整） ====
var_map <- list(
  br_group      = "group_rb",
  time_months   = "rfs_months",
  status_event  = "recur_tf",
  sex           = "sex",        # M/F または 0/1
  alb_gdl       = "Alb",        # g/dL
  tbil_mgdl     = "Tbil",       # mg/dL
  afp_ngml      = "AFP",        # ng/mL (= μg/L)
  size_mm       = "tum_diam_pre", # mm想定（mmなら自動でcmに変換）
  size_cm       = NA,           # 既にcm列があるなら列名を入れる。なければNAのままでOK
  tum_count     = "tum_count_pre",
  albi_grade    = NA,           # 既にgrade列があれば列名、無ければNAでAlb/Tbilから自動計算
  mvi01         = "mvi_01"      # 0/1
)

# ==== CHUNK2: ALBI計算 & 前処理ヘルパ ====
calc_albi <- function(alb_gdl = NULL, tbil_mgdl = NULL, alb_gL = NULL, tbil_umol = NULL){
  # 単位整合：Alb g/L, Tbil μmol/L に揃える
  alb_gL2   <- if(!is.null(alb_gL)) alb_gL else if(!is.null(alb_gdl)) alb_gdl*10 else NA_real_
  tbil_umol2<- if(!is.null(tbil_umol)) tbil_umol else if(!is.null(tbil_mgdl)) tbil_mgdl*17.104 else NA_real_
  score <- 0.66*log(tbil_umol2) - 0.085*alb_gL2
  grade <- cut(score, breaks = c(-Inf,-2.60,-1.39, Inf), labels = c(1L,2L,3L), right = TRUE)
  list(score = score, grade = as.integer(as.character(grade)))
}

# 必要列を安全に取り出す
getv <- function(df, name){
  if(is.na(name) || !name %in% names(df)) return(rep(NA, nrow(df)))
  df[[name]]
}

# ==== CHUNK3: ERASLスコア算出（BRのみ抽出） ====
compute_erasl_scores <- function(df, vm = var_map, restrict_BR = TRUE){
  d <- df

  # BRのみ
  if(restrict_BR && vm$br_group %in% names(d)){
    d <- d %>% filter(str_detect(.data[[vm$br_group]], "BR"))
  }

  # sex（Male=1, Female=0に正規化）
  sex_raw <- getv(d, vm$sex)
  sex_male <- case_when(
    is.numeric(sex_raw) ~ as.numeric(sex_raw),
    is.character(sex_raw) & str_detect(sex_raw, regex("^m|male|男性", ignore_case=TRUE)) ~ 1,
    is.character(sex_raw) & str_detect(sex_raw, regex("^f|female|女性", ignore_case=TRUE)) ~ 0,
    TRUE ~ NA_real_
  )

  # 腫瘍径cm：cm列があれば優先、無ければmm→cm（閾値で自動判定）
  size_cm <- if(!is.na(vm$size_cm) && vm$size_cm %in% names(d)) {
    as.numeric(d[[vm$size_cm]])
  } else {
    mm <- as.numeric(getv(d, vm$size_mm))
    if(all(is.na(mm))) NA_real_ else mm/10
  }

  # 腫瘍数カテゴリ（0:単発, 1:2-3個, 2:4個以上）
  tn <- as.numeric(getv(d, vm$tum_count))
  tum_cat <- case_when(
    !is.na(tn) & tn <= 1 ~ 0L,
    !is.na(tn) & tn %in% 2:3 ~ 1L,
    !is.na(tn) & tn >= 4 ~ 2L,
    TRUE ~ NA_integer_
  )

  # AFP（ln用; 0はlog不可なので1に底上げ）
  afp <- as.numeric(getv(d, vm$afp_ngml))
  ln_afp <- log(pmax(afp, 1))

  # ln(腫瘍径cm)（0や負値は欠損扱い）
  ln_size <- ifelse(is.finite(size_cm) & size_cm > 0, log(size_cm), NA_real_)

  # ALBI grade：列が無ければ算出
  if(!is.na(vm$albi_grade) && vm$albi_grade %in% names(d)){
    albi_grade <- as.integer(d[[vm$albi_grade]])
  } else {
    albi <- calc_albi(alb_gdl = as.numeric(getv(d, vm$alb_gdl)),
                      tbil_mgdl = as.numeric(getv(d, vm$tbil_mgdl)))
    albi_grade <- albi$grade
  }
  albi_bin <- ifelse(is.na(albi_grade), NA_integer_, ifelse(albi_grade >= 2, 1L, 0L))

  # MVI（0/1）
  mvi01 <- as.integer(getv(d, vm$mvi01))

  # --- ERASL式（論文Table 2） ---
  # ERASL-pre = 0.818*Male + 0.447*ALBI(2/3) + 0.100*lnAFP + 0.580*lnSize(cm) + 0.492*TumorNum(0/1/2)
  erasl_pre  <- 0.818*sex_male + 0.447*albi_bin + 0.100*ln_afp + 0.580*ln_size + 0.492*tum_cat
  # ERASL-post = 0.677*Male + 0.458*ALBI(2/3) + 0.661*MVI + 0.082*lnAFP + 0.451*lnSize + 0.379*TumorNum
  erasl_post <- 0.677*sex_male + 0.458*albi_bin + 0.661*mvi01 + 0.082*ln_afp + 0.451*ln_size + 0.379*tum_cat

  d %>%
    mutate(
      ERASL_pre  = erasl_pre,
      ERASL_post = erasl_post
    )
}

# ==== CHUNK4: 指標計算（Harrell’s c + 2年tdAUC） ====
calc_metrics <- function(d, score_col, time_col, status_col, t_month = 24, boot = 200, seed = 42){
  dd <- d %>%
    filter(is.finite(.data[[score_col]]),
           is.finite(.data[[time_col]]),
           !is.na(.data[[status_col]]))

  if(nrow(dd) < 10) stop("有効な症例が少なすぎます（<10）。")

  # Harrell's c（ブートでSE）
  set.seed(seed)
  c0 <- Hmisc::rcorr.cens(dd[[score_col]], Surv(dd[[time_col]], dd[[status_col]]))
  c_est <- unname(c0["C Index"])
  if(boot > 0){
    idxs <- replicate(boot, sample.int(nrow(dd), replace = TRUE), simplify = FALSE)
    c_vals <- vapply(idxs, function(i){
      d2 <- dd[i,]
      unname(Hmisc::rcorr.cens(d2[[score_col]], Surv(d2[[time_col]], d2[[status_col]]))["C Index"])
    }, numeric(1))
    c_se <- stats::sd(c_vals, na.rm = TRUE)
  } else {
    c_se <- NA_real_
  }

  # timeROC（iid=TRUEでSEを計算）※ 累積/ダイナミックROC
  tr <- timeROC::timeROC(T = dd[[time_col]],
                         delta = dd[[status_col]],
                         marker = dd[[score_col]],
                         cause = 1, times = c(t_month), iid = TRUE)
  auc_est <- as.numeric(tr$AUC[1])
  auc_se  <- as.numeric(tr$inference$vect_sd_1[1])

  tibble::tibble(
    model      = score_col,
    n          = nrow(dd),
    events     = sum(dd[[status_col]] == 1, na.rm = TRUE),
    c_index    = c_est,
    c_se       = c_se,
    tdAUC_t_mo = t_month,
    tdAUC      = auc_est,
    tdAUC_se   = auc_se
  )
}

# ==== CHUNK5: 実行例（df をあなたのデータフレーム名に置き換え） ====
# df <- your_dataframe
# BRのみでスコア付与
# df_scored <- compute_erasl_scores(df, var_map, restrict_BR = TRUE)

# 評価（Harrell's c と 2年tdAUC）
# res <- bind_rows(
#   calc_metrics(df_scored, "ERASL_pre",  var_map$time_months, var_map$status_event, t_month = 24, boot = 200),
#   calc_metrics(df_scored, "ERASL_post", var_map$time_months, var_map$status_event, t_month = 24, boot = 200)
# )
# print(res)

```

```{r}
# ==== Minimal: ERASL-pre/post → Harrell's c ＆ 2y tdAUC ====
suppressPackageStartupMessages({
  library(dplyr); library(survival); library(timeROC); library(tibble)
})

stopifnot(exists("ds02"))

# BRだけに絞る（列名が group_rb じゃない場合は適宜変更）
br <- ds02 %>% filter(grepl("BR", as.character(group_rb)))

# 腫瘍数カテゴリ（0:1個, 1:2-3個, 2:4個以上）
br <- br %>%
  mutate(tum_cat = case_when(
    tum_count <= 1 ~ 0L,
    tum_count %in% 2:3 ~ 1L,
    tum_count >= 4 ~ 2L,
    TRUE ~ NA_integer_
  ))

# ERASLスコア（論文の係数に合わせた線形予測子）
br <- br %>% mutate(
  ERASL_pre  = 0.818*sex_male + 0.447*albi23 + 0.100*ln_afp + 0.580*ln_diam + 0.492*tum_cat,
  ERASL_post = 0.677*sex_male + 0.458*albi23 + 0.661*mvi_01 + 0.082*ln_afp + 0.451*ln_diam + 0.379*tum_cat
)

# 共通テスト集合（完全ケース）
need_cols <- c("time","event","ERASL_pre","ERASL_post")
dd <- br %>% tidyr::drop_na(all_of(need_cols))
stopifnot(nrow(dd) >= 10)   # 少なすぎると推定が不安定

# Harrell's c（向きは reverse=TRUE）
cidx <- function(score) survival::concordance(Surv(dd$time, dd$event) ~ score, reverse = TRUE)$concordance

# 2年の time-dependent AUC（累積/ダイナミック）
td_auc_24 <- function(score) {
  tr <- timeROC(T = dd$time, delta = dd$event, marker = score, cause = 1, times = 24, iid = TRUE)
  unname(tr$AUC[1])
}

res <- tibble(
  model = c("ERASL_pre","ERASL_post"),
  n     = nrow(dd),
  events= sum(dd$event==1, na.rm = TRUE),
  c_index = c(cidx(dd$ERASL_pre), cidx(dd$ERASL_post)),
  tdAUC_24m = c(td_auc_24(dd$ERASL_pre), td_auc_24(dd$ERASL_post))
)

print(res)

```
ERASL-pre, ERASL-postのスコアは確かに良い。
上記のモデルと同じ方法で、BOrderline resectableのデータで作成してみる。

```{r}
# ==== ERASL-post方式（BRのみ・ds04_train→後退法→ds06_testで評価）====
suppressPackageStartupMessages({library(dplyr); library(survival); library(timeROC); library(tidyr); library(tibble)})

stopifnot(exists("ds04_train"), exists("ds06_test"))

# 学習・評価に不要な列は除外（必要ならここに追加）
drop_cols <- c("id","op_date","time","event","group_rb","group_rb_fill")
cand0 <- setdiff(names(ds04_train), drop_cols)

# 使える列だけ（全欠損/定数列を除外）。文字列は因子に。
is_const <- function(x) { ux <- unique(na.omit(x)); length(ux) < 2 }
ok <- cand0[sapply(ds04_train[cand0], function(z) any(!is.na(z)) && !is_const(z))]
train_base <- ds04_train %>% mutate(across(where(is.character), as.factor))
test_base  <- ds06_test  %>% mutate(across(where(is.character), as.factor))

## --- 単変量 p<0.20 のスクリーニング（FIX: namespace 明示） ---
keep <- c()
for(v in ok){
  # 存在しない列はスキップ
  if(!v %in% names(train_base)) next
  
  fm  <- as.formula(paste0("Surv(time, event) ~ `", v, "`"))
  dat <- train_base |>
    dplyr::select(time, event, dplyr::all_of(v)) |>
    tidyr::drop_na()
  
  if(nrow(dat) < 20 || sum(dat$event != 0) < 10) next
  
  fit <- try(survival::coxph(fm, data = dat, ties = "efron"), silent = TRUE)
  if(inherits(fit, "try-error")) next
  
  p <- tryCatch(coef(summary(fit))[1, "Pr(>|z|)"], error = function(e) NA_real_)
  if(is.finite(p) && p < 0.20) keep <- c(keep, v)
}
if(!length(keep)) stop("単変量で p<0.20 の候補がありません。")

## ---- FIX: robust univariate screen (ridge + impute + iter.max) ----
keep <- c()
ok   <- setdiff(ok, c("time","event"))  # 念のため

for(v in ok){
  if(!v %in% names(train_base)) next
  
  dat <- train_base |>
    dplyr::select(time, event, dplyr::all_of(v)) |>
    dplyr::filter(is.finite(time), time > 0, !is.na(event)) |>
    impute_simple()     # ★ 先に中央値/最頻でNA補完（drop_naしない）

  # 変数が実質定数/ユニーク<2ならスキップ
  x <- dat[[v]]
  if(sum(!is.na(x)) < 20 || length(unique(stats::na.omit(x))) < 2) next
  if(sum(dat$event != 0, na.rm = TRUE) < 10) next

  fm  <- stats::as.formula(paste0("Surv(time, event) ~ ridge(`", v, "`, theta=1e-6)"))
  fit <- try(
    survival::coxph(fm, data = dat, ties = "efron",
                    control = survival::coxph.control(iter.max = 50)),
    silent = TRUE
  )
  if(inherits(fit, "try-error")) next

  p <- tryCatch(coef(summary(fit))[1, "Pr(>|z|)"], error = function(e) NA_real_)
  if(is.finite(p) && p < 0.20) keep <- c(keep, v)
}
keep <- unique(keep)
if(!length(keep)) stop("単変量で p<0.20 の候補がありません。")


# --- Test評価（Harrell's c & 2年tdAUC） ---
dat_te <- test_base %>% select(time, event, all_of(keep)) %>% drop_na()
stopifnot(nrow(dat_te) >= 10)

lp_te <- predict(fit_erasl_post_BR, newdata=dat_te, type="lp")
cidx  <- survival::concordance(Surv(dat_te$time, dat_te$event) ~ lp_te, reverse=TRUE)$concordance
tr    <- timeROC(T=dat_te$time, delta=dat_te$event, marker=lp_te, cause=1, times=24, iid=TRUE)
auc24 <- unname(tr$AUC[1])

tibble(
  model        = "ERASL_post_style_BR (all-params→p<.20→backward p<.10)",
  n_train      = nrow(dat_tr),
  events_train = sum(dat_tr$event!=0),
  n_test       = nrow(dat_te),
  events_test  = sum(dat_te$event!=0),
  final_terms  = paste(keep, collapse=" + "),
  c_index      = cidx,
  tdAUC_24m    = auc24
)

```



